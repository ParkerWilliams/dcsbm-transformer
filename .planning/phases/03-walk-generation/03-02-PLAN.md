---
phase: 03-walk-generation
plan: 02
type: execute
wave: 2
depends_on:
  - 03-01
files_modified:
  - src/walk/corpus.py
  - src/walk/cache.py
  - src/walk/__init__.py
  - tests/test_walk_corpus.py
autonomous: true
requirements:
  - WALK-02
  - WALK-03
  - WALK-05

must_haves:
  truths:
    - "Training corpus contains at least 100n tokens (validated, fails with clear error if not)"
    - "Train and eval walk sets are generated independently with different seeds and share no walks"
    - "Walk corpus loads from cache on second call with same config hash"
    - "Walks and jumper event metadata are stored atomically in a single .npz archive"
    - "At least 50% of walks in the corpus contain a jumper encounter"
    - "Each jumper vertex has at least 3 distinct compliant paths in the corpus"
  artifacts:
    - path: "src/walk/corpus.py"
      provides: "Corpus assembly with train/eval split and validation"
      exports: ["generate_corpus", "validate_corpus"]
    - path: "src/walk/cache.py"
      provides: "Walk caching with config-hash-based keys"
      exports: ["walk_cache_key", "save_walks", "load_walks", "generate_or_load_walks"]
    - path: "src/walk/__init__.py"
      provides: "Public API for walk module"
      exports: ["generate_or_load_walks", "generate_corpus"]
    - path: "tests/test_walk_corpus.py"
      provides: "Tests for corpus assembly, validation, and caching"
      min_lines: 80
  key_links:
    - from: "src/walk/corpus.py"
      to: "src/walk/generator.py"
      via: "generate_walks called for train and eval sets separately"
      pattern: "generate_walks\\("
    - from: "src/walk/cache.py"
      to: "src/config/hashing.py"
      via: "graph_config_hash used in walk cache key construction"
      pattern: "graph_config_hash\\("
    - from: "src/walk/cache.py"
      to: "numpy"
      via: "np.savez_compressed for atomic .npz storage"
      pattern: "savez_compressed"
---

<objective>
Implement corpus assembly with train/eval splitting, corpus size validation, atomic NPZ storage with jumper event metadata, and walk caching by config hash.

Purpose: Provide the complete walk data pipeline that produces cached, validated train and eval corpora ready for transformer training (Phase 5) and evaluation (Phase 6).

Output: `src/walk/corpus.py`, `src/walk/cache.py`, updated `src/walk/__init__.py` with public API; test suite proving corpus correctness and cache behavior.
</objective>

<execution_context>
@/root/.claude/get-shit-done/workflows/execute-plan.md
@/root/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-walk-generation/03-CONTEXT.md
@.planning/phases/03-walk-generation/03-RESEARCH.md
@.planning/phases/03-walk-generation/03-01-SUMMARY.md

@src/walk/types.py
@src/walk/generator.py
@src/walk/compliance.py
@src/graph/cache.py
@src/config/experiment.py
@src/config/hashing.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Corpus assembly and validation</name>
  <files>
    src/walk/corpus.py
  </files>
  <action>
**src/walk/corpus.py** — Corpus assembly with train/eval splitting and validation:

1. `validate_corpus(walks: np.ndarray, events: list[list[JumperEvent]], graph_data: GraphData, jumpers: list[JumperInfo], min_jumper_fraction: float = 0.5, min_paths_per_jumper: int = 3) -> list[str]`:
   - Returns list of error strings (empty = valid)
   - Check corpus size: walks.shape[0] (number of walks) is provided; caller validates against 100n threshold
   - Check jumper fraction: count walks with at least one event >= min_jumper_fraction of total walks
   - Check path diversity: for each jumper vertex in jumpers, collect the walk segments from encounter step to arrival step across all events for that jumper. Count distinct segments (as tuples). Must have >= min_paths_per_jumper distinct paths.
   - Check edge validity: for each walk, verify walk[step+1] is a neighbor of walk[step] in graph_data.adjacency (sample-based check — verify 100 random walks to avoid O(n*L) cost on full corpus)
   - Check rule compliance: for each event where expected_arrival_step < walk_length, verify block_assignments[walk[expected_arrival_step]] == target_block
   - Return all found errors as descriptive strings

2. `generate_corpus(graph_data: GraphData, jumpers: list[JumperInfo], config: ExperimentConfig) -> tuple[WalkResult, WalkResult]`:
   - Compute walk_length from config.training.walk_length
   - Compute n_train = config.training.corpus_size (the 100n threshold applies to train alone per CONTEXT pitfall 5)
   - Compute n_eval = max(1, n_train // 9) so that train is ~90% and eval is ~10% of total (train:eval = 9:1)
   - Train seed = config.seed + 2000 (offset to avoid correlation with graph seed and jumper seed)
   - Eval seed = config.seed + 3000
   - Generate train walks: generate_walks(graph_data, jumpers, config, seed=train_seed, target_n_walks=n_train)
   - Generate eval walks: generate_walks(graph_data, jumpers, config, seed=eval_seed, target_n_walks=n_eval)
   - Validate train corpus: call validate_corpus(). If errors, raise ValueError with joined error messages.
   - Validate that n_train >= 100 * config.graph.n. If not, raise ValueError with clear message: f"Training corpus size {n_train} is less than 100 * n ({100 * config.graph.n}). Increase corpus_size."
   - Validate eval corpus (same checks, but no 100n threshold)
   - Log corpus statistics: total walks, jumper fraction, unique jumper paths, walk length
   - Return (train_result, eval_result)

Key implementation notes:
- Train and eval use completely independent RNG seeds — no overlap by construction per CONTEXT decision
- The 100n threshold check is also in ExperimentConfig.__post_init__, but validate here too as a defense-in-depth after any discards/regeneration
- Per CONTEXT: "After any filtering/discards, corpus is regenerated to maintain size requirement" — generate_walks in Plan 01 handles this internally
  </action>
  <verify>
    <automated>cd /root/Repos/dcsbm-transformer && python -c "
from src.walk.corpus import generate_corpus, validate_corpus
print('Corpus module imports OK')
"</automated>
    <manual>Verify generate_corpus produces correct train/eval split ratios</manual>
  </verify>
  <done>generate_corpus() produces independent train and eval WalkResult objects with correct seed separation; validate_corpus() checks jumper fraction, path diversity, edge validity, and rule compliance; training corpus size validated against 100n threshold with clear error on failure.</done>
</task>

<task type="auto">
  <name>Task 2: Walk caching, public API, and integration tests</name>
  <files>
    src/walk/cache.py
    src/walk/__init__.py
    tests/test_walk_corpus.py
  </files>
  <action>
**src/walk/cache.py** — Walk caching following Phase 2 graph cache pattern:

1. `walk_cache_key(config: ExperimentConfig, split: str, seed: int) -> str`:
   - Compute hash of: graph_config_hash(config) + walk_length + corpus_size + split + seed
   - Use hashlib.sha256 on JSON-serialized dict of these params (sorted keys, compact separators — same pattern as config_hash in src/config/hashing.py)
   - Return first 16 hex chars + f"_{split}" suffix (e.g., "a1b2c3d4e5f6g7h8_train")

2. `save_walks(walk_result: WalkResult, config: ExperimentConfig, split: str, seed: int, cache_dir: Path = DEFAULT_CACHE_DIR) -> Path`:
   - DEFAULT_CACHE_DIR = Path(".cache/walks") — same parent cache location as graphs per CONTEXT
   - Compute cache key, create directory
   - Use np.savez_compressed to save atomically in single .npz file (per CONTEXT: walks and metadata always in sync):
     - `walks`: walk_result.walks (int32 array, num_walks x walk_length)
     - `walk_seeds`: walk_result.walk_seeds (int64 array)
     - `event_walk_ids`: int32 array of walk indices for each event
     - `event_vertex_ids`: int32 array of vertex_id for each event
     - `event_steps`: int32 array of step for each event
     - `event_target_blocks`: int32 array of target_block for each event
     - `event_arrival_steps`: int32 array of expected_arrival_step for each event
     - `num_walks`: scalar array of walks.shape[0]
     - `walk_length`: scalar array of walks.shape[1]
   - Flatten events from list[list[JumperEvent]] into parallel arrays (per research NPZ example)
   - Return path to saved .npz file

3. `load_walks(config: ExperimentConfig, split: str, seed: int, cache_dir: Path = DEFAULT_CACHE_DIR) -> WalkResult | None`:
   - Compute cache key, check if .npz file exists
   - If not found: return None
   - Load .npz, reconstruct WalkResult:
     - walks from 'walks' array
     - walk_seeds from 'walk_seeds' array
     - Reconstruct events list[list[JumperEvent]] from flat event arrays by grouping on event_walk_ids
   - Return WalkResult

4. `generate_or_load_walks(graph_data: GraphData, jumpers: list[JumperInfo], config: ExperimentConfig, cache_dir: Path = DEFAULT_CACHE_DIR) -> tuple[WalkResult, WalkResult]`:
   - Compute train_seed = config.seed + 2000, eval_seed = config.seed + 3000
   - Try load_walks for train split. If cache hit, try load_walks for eval split. If both hit, return both.
   - On any cache miss: call generate_corpus() to generate both, then save both to cache
   - Log cache hit/miss status
   - Return (train_result, eval_result)

**src/walk/__init__.py** — Public API:
```python
from src.walk.cache import generate_or_load_walks, load_walks, save_walks, walk_cache_key
from src.walk.corpus import generate_corpus, validate_corpus
from src.walk.generator import generate_walks
from src.walk.types import JumperEvent, WalkResult

__all__ = [
    "JumperEvent", "WalkResult",
    "generate_walks",
    "generate_corpus", "validate_corpus",
    "generate_or_load_walks", "load_walks", "save_walks", "walk_cache_key",
]
```

**tests/test_walk_corpus.py** — Tests:

1. `test_train_eval_different_seeds`: Call generate_corpus, verify train and eval walks differ (not identical arrays).
2. `test_train_corpus_size_validation`: Create config with corpus_size = 100 * n, verify generate_corpus succeeds. Then try with corpus_size = 50 * n (should fail in ExperimentConfig first, but test validate_corpus separately).
3. `test_corpus_jumper_fraction`: Verify at least 50% of walks in train corpus contain jumper events.
4. `test_corpus_path_diversity`: Verify each jumper has at least 3 distinct compliant paths in the corpus.
5. `test_cache_save_load_roundtrip`: Save walk result to temp cache dir, load back, verify walks and events are identical.
6. `test_cache_hit_skips_generation`: Call generate_or_load_walks twice, verify second call is faster (cache hit).
7. `test_cache_key_includes_graph_hash`: Verify walk_cache_key changes when graph config changes.
8. `test_npz_atomic_storage`: Load saved .npz file, verify both walks and event arrays are present in same archive.
9. `test_90_10_split_ratio`: Verify n_eval is approximately n_train / 9.

Use the anchor config for integration tests (3-6). Use small configs for unit tests (1, 2, 7-9).

For tests requiring graph data, use generate_or_load_graph from src/graph to get a real graph (with caching so tests are fast on re-run), or create small synthetic test graphs for pure unit tests.
  </action>
  <verify>
    <automated>cd /root/Repos/dcsbm-transformer && python -m pytest tests/test_walk_corpus.py -x -v 2>&1 | tail -30</automated>
    <manual>Verify cache hit message appears in logs on second call</manual>
  </verify>
  <done>Walk caching with config-hash keys saves/loads .npz files atomically; generate_or_load_walks transparently caches both train and eval sets; public API exported from src/walk/__init__.py; at least 9 tests pass covering seed independence, size validation, jumper fraction, path diversity, cache roundtrip, cache hit behavior, key computation, atomic storage, and split ratios.</done>
</task>

</tasks>

<verification>
1. Training corpus has >= 100n walks (validated with error on failure)
2. Train and eval walks generated with different seeds (no overlap by construction)
3. Walk cache hit on second call with same config (no regeneration)
4. .npz files contain both walks and event metadata atomically
5. At least 50% of corpus walks contain jumper encounters
6. Each jumper has >= 3 distinct compliant paths in corpus
7. `python -m pytest tests/test_walk_corpus.py -x` passes
</verification>

<success_criteria>
- `src/walk/corpus.py` implements generate_corpus with train/eval splitting and validate_corpus
- `src/walk/cache.py` implements walk caching following Phase 2 pattern
- `src/walk/__init__.py` exports full public API
- All tests in `tests/test_walk_corpus.py` pass
- Walk caching produces cache hits on identical config
- NPZ archives contain both walks and metadata in single file
</success_criteria>

<output>
After completion, create `.planning/phases/03-walk-generation/03-02-SUMMARY.md`
</output>
