---
phase: 08-visualization
plan: 01
type: tdd
wave: 1
depends_on: []
files_modified:
  - pyproject.toml
  - src/visualization/__init__.py
  - src/visualization/style.py
  - src/visualization/event_aligned.py
  - src/visualization/training.py
  - src/visualization/auroc.py
  - src/visualization/confusion.py
  - tests/test_visualization.py
autonomous: true
requirements:
  - PLOT-01
  - PLOT-02
  - PLOT-03
  - PLOT-04
  - PLOT-07
  - PLOT-08

must_haves:
  truths:
    - "Event-aligned SVD metric plots show position 0 = failure event with negative positions before and positive after, with confidence bands and correct-sequence baseline overlay"
    - "Training convergence curves plot loss per step and edge/rule compliance per epoch with gate threshold reference lines"
    - "AUROC vs lookback distance curves render per metric with threshold and chance reference lines, and optional horizon marker"
    - "Confusion matrix renders 4-class behavioral outcomes (edge valid/invalid x rule followed/violated) with counts and percentages"
    - "All plots use seaborn whitegrid style with a consistent colorblind-safe palette"
    - "All figures are saved as both PNG (300 dpi) and SVG"
  artifacts:
    - path: "src/visualization/__init__.py"
      provides: "Public API for visualization module"
    - path: "src/visualization/style.py"
      provides: "apply_style(), save_figure(), PALETTE, VIOLATION_COLOR, CONTROL_COLOR"
      contains: "def apply_style"
    - path: "src/visualization/event_aligned.py"
      provides: "plot_event_aligned() for PLOT-01"
      contains: "def plot_event_aligned"
    - path: "src/visualization/training.py"
      provides: "plot_training_curves() for PLOT-02"
      contains: "def plot_training_curves"
    - path: "src/visualization/auroc.py"
      provides: "plot_auroc_curves() for PLOT-03"
      contains: "def plot_auroc_curves"
    - path: "src/visualization/confusion.py"
      provides: "plot_confusion_matrix() for PLOT-04"
      contains: "def plot_confusion_matrix"
    - path: "tests/test_visualization.py"
      provides: "Tests for style, save, and all four core plot types"
  key_links:
    - from: "src/visualization/style.py"
      to: "seaborn"
      via: "sns.set_theme(style='whitegrid')"
      pattern: "sns\\.set_theme.*whitegrid"
    - from: "src/visualization/event_aligned.py"
      to: "src/analysis/event_extraction.py"
      via: "AnalysisEvent import for event alignment"
      pattern: "from src\\.analysis\\.event_extraction import"
    - from: "src/visualization/confusion.py"
      to: "src/evaluation/behavioral.py"
      via: "RuleOutcome enum for class labeling"
      pattern: "from src\\.evaluation\\.behavioral import RuleOutcome"
---

<objective>
Implement the visualization style foundation and four core plot types: event-aligned SVD metric plots, training convergence curves, AUROC vs lookback distance curves, and confusion matrices.

Purpose: These are the foundational visualization functions that render the project's primary analysis results as publication-quality static figures. The style module ensures all plots share a consistent visual identity (seaborn whitegrid + colorblind-safe palette), and the dual-format save helper guarantees PNG + SVG output.

Output: A `src/visualization/` package with style.py, event_aligned.py, training.py, auroc.py, confusion.py, and comprehensive test coverage.
</objective>

<execution_context>
@/root/.claude/get-shit-done/workflows/execute-plan.md
@/root/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/08-visualization/08-CONTEXT.md
@.planning/phases/08-visualization/08-RESEARCH.md
@src/analysis/event_extraction.py
@src/analysis/auroc_horizon.py
@src/evaluation/behavioral.py
@src/evaluation/pipeline.py
@src/training/pipeline.py
@src/results/schema.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Style foundation, save helper, and dependencies (TDD)</name>
  <files>
    pyproject.toml
    src/visualization/__init__.py
    src/visualization/style.py
    tests/test_visualization.py
  </files>
  <action>
**Install dependencies first:**

Add matplotlib and seaborn to pyproject.toml dependencies:
```toml
dependencies = [
    "torch>=2.0",
    "numpy>=2.0",
    "dacite>=1.8",
    "scipy>=1.14",
    "matplotlib>=3.8",
    "seaborn>=0.13",
]
```

Then run: `.venv/bin/pip install -e .` to install them.

**RED phase: Write tests first in tests/test_visualization.py**

Create test file with these test cases:

1. `test_apply_style_sets_whitegrid` -- Call `apply_style()`, then check `matplotlib.rcParams` contains expected settings: savefig.dpi == 300. Also verify seaborn's whitegrid is active by checking rcParams['axes.grid'] is True.

2. `test_save_figure_creates_png_and_svg` -- Create a simple figure with `plt.figure()`, call `save_figure(fig, tmp_path, "test_plot")`. Verify both `test_plot.png` and `test_plot.svg` exist in tmp_path. Verify the PNG is non-empty. Verify the figure was closed (fig.get_size_inches() raises or figure not in plt.get_fignums()).

3. `test_save_figure_creates_directory` -- Call save_figure with a non-existent subdirectory path. Verify it creates the directory and saves both files.

4. `test_palette_is_colorblind_safe` -- Verify PALETTE has at least 8 colors. Verify VIOLATION_COLOR and CONTROL_COLOR are defined and are valid RGB tuples.

5. `test_apply_style_idempotent` -- Call apply_style() twice. Second call should not raise or change behavior.

**GREEN phase: Implement**

Create `src/visualization/__init__.py`:
```python
"""Publication-quality static figure generation."""
```

Create `src/visualization/style.py`:
```python
"""Consistent visual style for all project figures.

Sets seaborn whitegrid theme with a colorblind-safe palette.
Provides save_figure() helper for dual PNG/SVG output (PLOT-07, PLOT-08).
"""
import matplotlib
matplotlib.use("Agg")  # Non-interactive backend for headless rendering
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path

# Colorblind-safe palette (seaborn 'colorblind' preset)
PALETTE = sns.color_palette("colorblind", n_colors=8)
VIOLATION_COLOR = PALETTE[3]  # red-ish
CONTROL_COLOR = PALETTE[0]    # blue-ish
BASELINE_COLOR = PALETTE[2]   # green-ish
THRESHOLD_COLOR = (0.5, 0.5, 0.5)  # gray

def apply_style():
    """Apply project-wide matplotlib/seaborn style (PLOT-07).

    Sets seaborn whitegrid, configures font sizes for publication,
    sets DPI for high-resolution output.
    """
    sns.set_theme(style="whitegrid")
    plt.rcParams.update({
        "figure.dpi": 150,
        "savefig.dpi": 300,
        "font.size": 10,
        "axes.titlesize": 12,
        "axes.labelsize": 11,
        "legend.fontsize": 9,
        "xtick.labelsize": 9,
        "ytick.labelsize": 9,
        "figure.figsize": (8, 5),
        "svg.fonttype": "none",  # Embed text as SVG text elements
    })


def save_figure(fig: plt.Figure, output_dir: Path, name: str) -> tuple[Path, Path]:
    """Save figure as both PNG (300 dpi) and SVG (PLOT-08).

    Args:
        fig: Matplotlib figure to save.
        output_dir: Directory to write files into. Created if absent.
        name: Base filename (without extension).

    Returns:
        Tuple of (png_path, svg_path).
    """
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    png_path = output_dir / f"{name}.png"
    svg_path = output_dir / f"{name}.svg"
    fig.savefig(png_path, dpi=300, bbox_inches="tight")
    fig.savefig(svg_path, bbox_inches="tight")
    plt.close(fig)
    return png_path, svg_path
```

Run tests: `.venv/bin/pytest tests/test_visualization.py -x -v -k "style or save or palette"`
  </action>
  <verify>
    <automated>.venv/bin/pytest tests/test_visualization.py -x -v -k "style or save or palette"</automated>
    <manual>Verify apply_style sets whitegrid and save_figure produces both PNG and SVG</manual>
    <sampling_rate>run after this task commits, before next task begins</sampling_rate>
  </verify>
  <done>
    - matplotlib and seaborn installed and in pyproject.toml
    - apply_style() sets seaborn whitegrid with publication-quality rcParams
    - save_figure() writes both PNG (300 dpi) and SVG, creates directories, closes figure
    - PALETTE is colorblind-safe with VIOLATION_COLOR and CONTROL_COLOR defined
    - All 5 style/save tests pass
  </done>
</task>

<task type="auto">
  <name>Task 2: Core plot types -- event-aligned, training, AUROC, confusion (TDD)</name>
  <files>
    src/visualization/event_aligned.py
    src/visualization/training.py
    src/visualization/auroc.py
    src/visualization/confusion.py
    tests/test_visualization.py
  </files>
  <action>
**RED phase: Add tests to tests/test_visualization.py**

Add these test cases (each plot function receives pre-loaded data, not file paths):

6. `test_event_aligned_plot_returns_figure` -- Create synthetic metric_values array (20 sequences x 100 steps), synthetic AnalysisEvent list (5 violations, 10 controls) with known resolution_steps, and a failure_index array. Call `plot_event_aligned(metric_values, events, window=10, metric_name="qkt.stable_rank")`. Verify it returns a matplotlib Figure. Verify the figure has at least 1 axes. Save with save_figure and verify PNG/SVG are non-empty.

7. `test_event_aligned_plot_has_two_traces` -- After plotting, check that the axes has at least 2 lines (violation trace + control/baseline trace) via `len(ax.get_lines()) >= 2`.

8. `test_event_aligned_handles_nan` -- Create metric_values with NaN in early positions (warmup). Verify plot_event_aligned does not raise, produces a valid figure.

9. `test_training_curves_returns_figure` -- Create synthetic curves dict: train_loss (1000 float values decreasing), edge_compliance (50 float values increasing to 0.97), rule_compliance (50 float values increasing to 0.85). Call `plot_training_curves(curves)`. Verify returns Figure with 2 axes (loss + compliance subplots).

10. `test_training_curves_shows_thresholds` -- After plotting compliance axes, verify there are horizontal reference lines (at least 2 lines in the compliance subplot for the gate thresholds).

11. `test_auroc_curve_returns_figure` -- Create a dict of auroc results: `{"metric_a": {"auroc_by_lookback": [0.5, 0.6, 0.7, 0.8, 0.75, 0.65], "horizon": 4}}`. Call `plot_auroc_curves(auroc_results, r_value=6)`. Verify returns Figure.

12. `test_auroc_curve_shows_threshold_line` -- Verify the axes has a horizontal dashed line at 0.75 (threshold) and at 0.5 (chance).

13. `test_confusion_matrix_returns_figure` -- Create synthetic edge_valid (bool array) and rule_outcome (int array with RuleOutcome values). Call `plot_confusion_matrix(edge_valid, rule_outcome)`. Verify returns Figure with one axes containing a heatmap.

14. `test_confusion_matrix_counts` -- With known counts (e.g., 100 edge_valid+followed, 20 edge_valid+violated, 5 edge_invalid+followed, 3 edge_invalid+violated), verify the confusion matrix data sums correctly.

**GREEN phase: Implement the four plot modules**

**src/visualization/event_aligned.py (PLOT-01):**
```python
def plot_event_aligned(
    metric_values: np.ndarray,   # [n_sequences, max_steps]
    events: list[AnalysisEvent],
    window: int = 10,
    metric_name: str = "SVD metric",
    ax: plt.Axes | None = None,
) -> plt.Figure:
```
- Separate events into violations (outcome == RuleOutcome.VIOLATED) and controls (outcome == RuleOutcome.FOLLOWED)
- For each group, collect metric values at relative positions -window..+window aligned to resolution_step (position 0 = failure event)
- Compute nanmean and 95% CI (1.96 * nanstd / sqrt(n)) across events per position
- Plot mean line + fill_between for CI, one trace per group
- Add vertical dashed line at position 0 ("Failure event")
- Labels, legend, axis titles

**src/visualization/training.py (PLOT-02):**
```python
def plot_training_curves(
    curves: dict[str, list[float]],
    gate_thresholds: dict[str, float] | None = None,
) -> plt.Figure:
```
- Create figure with 2 subplots (1 row, 2 cols or 2 rows, 1 col)
- Left/top: train_loss vs step number
- Right/bottom: edge_compliance and rule_compliance vs epoch
- Add horizontal reference lines at thresholds (default: edge=0.95, rule=0.80) as dashed gray lines
- X-axis labeled "Training step" / "Epoch", Y-axis labeled accordingly

**src/visualization/auroc.py (PLOT-03):**
```python
def plot_auroc_curves(
    auroc_results: dict[str, dict],
    r_value: int,
    threshold: float = 0.75,
    ax: plt.Axes | None = None,
) -> plt.Figure:
```
- auroc_results maps metric_name -> {"auroc_by_lookback": [...], "horizon": int, optionally "bootstrap_ci": [...]}
- Plot each metric's AUROC curve vs lookback distance j (1..r)
- Add horizontal dashed lines at threshold (0.75) and chance (0.5)
- If bootstrap_ci available, add confidence bands via fill_between
- Optional horizon marker as vertical dotted line
- Use PALETTE colors cycling per metric, with legend

**src/visualization/confusion.py (PLOT-04):**
```python
def plot_confusion_matrix(
    edge_valid: np.ndarray,
    rule_outcome: np.ndarray,
) -> plt.Figure:
```
- Build 2x2 confusion matrix:
  - Rows: Edge valid / Edge invalid
  - Cols: Rule followed / Rule violated
- Count occurrences where rule_outcome == RuleOutcome.FOLLOWED and rule_outcome == RuleOutcome.VIOLATED, split by edge_valid True/False
- Ignore NOT_APPLICABLE steps
- Use seaborn heatmap with annotations showing both count and percentage
- Color scale: Blues or sequential palette

Run all tests: `.venv/bin/pytest tests/test_visualization.py -x -v`
  </action>
  <verify>
    <automated>.venv/bin/pytest tests/test_visualization.py -x -v</automated>
    <manual>Verify all four plot types produce valid figures with expected visual elements</manual>
    <sampling_rate>run after this task commits, before next task begins</sampling_rate>
  </verify>
  <done>
    - Event-aligned plots show violation and control traces with CI bands aligned to position 0 = failure
    - Training curves show loss + compliance with gate threshold reference lines
    - AUROC curves show per-metric lines with threshold and chance reference
    - Confusion matrix shows 4-class counts with seaborn heatmap
    - All 14 tests pass
    - No regressions in existing test suite
  </done>
</task>

</tasks>

<verification>
```bash
# All visualization tests pass
.venv/bin/pytest tests/test_visualization.py -x -v

# No regressions in existing tests
.venv/bin/pytest tests/ -x --timeout=120

# Verify module is importable
.venv/bin/python -c "from src.visualization.style import apply_style, save_figure, PALETTE; print('style OK')"
.venv/bin/python -c "from src.visualization.event_aligned import plot_event_aligned; print('event_aligned OK')"
.venv/bin/python -c "from src.visualization.training import plot_training_curves; print('training OK')"
.venv/bin/python -c "from src.visualization.auroc import plot_auroc_curves; print('auroc OK')"
.venv/bin/python -c "from src.visualization.confusion import plot_confusion_matrix; print('confusion OK')"
```
</verification>

<success_criteria>
- matplotlib and seaborn installed and declared in pyproject.toml
- Style module applies seaborn whitegrid with colorblind-safe palette (PLOT-07)
- save_figure writes both PNG (300 dpi) and SVG (PLOT-08)
- Event-aligned SVD metric plots show position 0 = failure, negative before, positive after, with confidence bands (PLOT-01)
- Training convergence curves plot loss and compliance with threshold reference lines (PLOT-02)
- AUROC vs lookback distance curves render per metric with threshold and chance markers (PLOT-03)
- Confusion matrix renders 4-class behavioral outcomes (PLOT-04)
- All tests pass with no regressions
</success_criteria>

<output>
After completion, create `.planning/phases/08-visualization/08-01-SUMMARY.md`
</output>
