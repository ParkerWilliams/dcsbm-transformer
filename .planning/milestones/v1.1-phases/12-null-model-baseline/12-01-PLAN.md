---
phase: 12-null-model-baseline
plan: 01
type: tdd
wave: 1
depends_on: []
files_modified:
  - src/analysis/null_model.py
  - tests/test_null_model.py
autonomous: true
requirements:
  - NULL-01
  - NULL-03

must_haves:
  truths:
    - "generate_null_walks() produces walks on the full graph that never visit a jumper vertex, using the same model and graph as the violation experiment"
    - "Null walks are 5x the violation walk count, position-matched (same walk length, same measurement positions)"
    - "run_null_evaluation() feeds null walks through the trained model via fused_evaluate and extracts Grassmannian drift at position-matched lookback distances"
    - "marchenko_pastur_pdf() and marchenko_pastur_cdf() compute the MP distribution with correct parameterization (gamma = w/d_model, sigma2 calibrated from data)"
    - "run_mp_ks_test() compares empirical QK^T squared singular values against MP CDF at anchor positions (event, pre-event, post-event) using scipy.stats.kstest"
  artifacts:
    - path: "src/analysis/null_model.py"
      provides: "Null walk generator, null evaluation pipeline, MP reference computation"
      exports: ["generate_null_walks", "run_null_evaluation", "extract_position_matched_drift", "marchenko_pastur_pdf", "marchenko_pastur_cdf", "run_mp_ks_test"]
    - path: "tests/test_null_model.py"
      provides: "Tests for null walk generation, position-matched drift extraction, MP distribution, and KS test"
  key_links:
    - from: "src/analysis/null_model.py"
      to: "src/walk/generator.py"
      via: "generate_batch_unguided_walks for null walk generation on filtered adjacency"
      pattern: "from src\\.walk\\.generator import generate_batch_unguided_walks"
    - from: "src/analysis/null_model.py"
      to: "src/evaluation/pipeline.py"
      via: "fused_evaluate for running null walks through the trained model"
      pattern: "from src\\.evaluation\\.pipeline import fused_evaluate"
    - from: "src/analysis/null_model.py"
      to: "scipy.stats"
      via: "kstest for Marchenko-Pastur comparison"
      pattern: "from scipy\\.stats import kstest"
    - from: "src/analysis/null_model.py"
      to: "scipy.integrate"
      via: "quad for MP CDF numerical integration"
      pattern: "from scipy\\.integrate import quad"
---

<objective>
Implement the null walk generator, null evaluation pipeline, and Marchenko-Pastur reference distribution as a standalone analysis module.

Purpose: Provide the foundation for Phase 12's null model baseline. Null walks (jumper-free sequences) establish the noise floor for Grassmannian drift, and the MP reference distribution grounds the interpretation of QK^T singular values against random matrix theory. Plan 12-02 depends on the outputs of this plan for statistical comparison, result.json storage, and visualization.

Output: `src/analysis/null_model.py` with null walk generation, null evaluation, position-matched drift extraction, and MP reference functions. `tests/test_null_model.py` with comprehensive tests.
</objective>

<execution_context>
@/root/.claude/get-shit-done/workflows/execute-plan.md
@/root/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/12-null-model-baseline/12-CONTEXT.md
@.planning/phases/12-null-model-baseline/12-RESEARCH.md
@src/walk/generator.py
@src/evaluation/pipeline.py
@src/graph/types.py
@src/graph/jumpers.py
@src/analysis/statistical_controls.py
@src/config/experiment.py

<interfaces>
<!-- Key types and contracts the executor needs. Extracted from codebase. -->

From src/graph/types.py:
```python
@dataclass(frozen=True)
class GraphData:
    adjacency: scipy.sparse.csr_matrix  # directed adjacency (n x n)
    block_assignments: np.ndarray        # int array [n], vertex -> block
    theta: np.ndarray                    # float array [n], degree correction
    n: int                               # number of vertices
    K: int                               # number of blocks
    block_size: int                      # vertices per block (n // K)
    generation_seed: int
    attempt: int
```

From src/graph/jumpers.py:
```python
@dataclass(frozen=True, slots=True)
class JumperInfo:
    vertex_id: int
    source_block: int
    target_block: int
    r: int  # jump length in steps
```

From src/walk/generator.py:
```python
def generate_batch_unguided_walks(
    start_vertices: np.ndarray,  # [n_walks]
    walk_length: int,
    rng: np.random.Generator,
    indptr: np.ndarray,          # CSR row pointer
    indices: np.ndarray,         # CSR column indices
) -> np.ndarray:
    # Returns [n_walks, walk_length] int32 array
```

From src/evaluation/pipeline.py:
```python
@dataclass
class EvaluationResult:
    generated: np.ndarray           # [n_sequences, max_steps]
    edge_valid: np.ndarray          # [n_sequences, max_steps-1]
    rule_outcome: np.ndarray        # [n_sequences, max_steps-1]
    failure_index: np.ndarray       # [n_sequences] -- -1 if no violation
    svd_metrics: dict[str, np.ndarray]  # target.layer.metric -> [n_seq, max_steps-1]
    guard_activations: dict[str, int]
    sequence_lengths: np.ndarray    # [n_sequences]

def fused_evaluate(
    model: nn.Module,
    eval_walks: np.ndarray,        # [N, walk_length]
    graph_data: GraphData,
    jumpers: list[JumperInfo],
    config: ExperimentConfig,
    device: torch.device,
    batch_size: int = 32,
) -> EvaluationResult:
```

From src/config/experiment.py:
```python
@dataclass(frozen=True, slots=True)
class ExperimentConfig:
    graph: GraphConfig       # n=500, K=4, p_in=0.25, p_out=0.03
    model: ModelConfig       # d_model=128, n_layers=4, n_heads=1
    training: TrainingConfig # w=64, walk_length=256, r=57
    sweep: SweepConfig | None = None
    seed: int = 42
    description: str = ""
    tags: tuple[str, ...] = ()
```

From src/analysis/statistical_controls.py:
```python
def holm_bonferroni(p_values: np.ndarray, alpha: float = 0.05) -> tuple[np.ndarray, np.ndarray]
    # Returns (adjusted_p_values, reject_flags)

def cohens_d(group1: np.ndarray, group2: np.ndarray) -> float
    # Returns Cohen's d with pooled standard deviation
```
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Write tests for null walk generation, drift extraction, and MP reference</name>
  <files>
    tests/test_null_model.py
  </files>
  <action>
Create `tests/test_null_model.py` with the following test cases. These tests must be written FIRST (RED phase) and should FAIL until Task 2 implements the module.

**Null Walk Generation Tests:**

1. `test_generate_null_walks_no_jumpers_visited` -- Create a small DCSBM graph (n=20, K=2) with 2 jumper vertices. Call `generate_null_walks()`. Assert that NO vertex in ANY walk is a jumper vertex. Use `set(walk.flatten()) & jumper_set == set()`.

2. `test_generate_null_walks_correct_count` -- Request 50 null walks. Assert output shape is `(50, walk_length)`.

3. `test_generate_null_walks_edge_validity` -- For each consecutive pair in every null walk, verify the edge exists in the graph's adjacency matrix (CSR lookup). Sample-check at least 10 walks.

4. `test_generate_null_walks_deterministic` -- Call `generate_null_walks()` twice with the same seed. Assert arrays are identical (`np.array_equal`).

5. `test_generate_null_walks_different_seeds` -- Call with two different seeds. Assert arrays differ.

6. `test_generate_null_walks_handles_dead_ends` -- Create a graph where removing jumper columns from the adjacency creates a vertex with 0 out-degree in the filtered graph. Verify the function handles this gracefully (either avoids starting there or uses random restart). The function should not hang or crash.

**Position-Matched Drift Extraction Tests:**

7. `test_extract_position_matched_drift_correct_positions` -- Create a synthetic metric array [10, 100] with known values. Define 3 event positions (e.g., 30, 50, 70). Call `extract_position_matched_drift()` with lookback distances j=1..5. Verify returned values match `metric_array[:, position - j]` for each j and position.

8. `test_extract_position_matched_drift_nan_filtering` -- Inject NaN values at specific positions. Verify the output filters NaN values and only returns finite values.

9. `test_extract_position_matched_drift_out_of_bounds` -- Use positions that would result in negative indices for large j. Verify these are gracefully skipped (no crash, returns fewer values).

**Marchenko-Pastur Tests:**

10. `test_marchenko_pastur_pdf_support` -- For gamma=0.5, sigma2=1.0, verify PDF is zero outside [lambda_minus, lambda_plus] = [(1-sqrt(0.5))^2, (1+sqrt(0.5))^2]. Verify PDF > 0 inside the support at the midpoint.

11. `test_marchenko_pastur_pdf_integrates_to_one` -- Numerically integrate MP PDF from lambda_minus to lambda_plus using `scipy.integrate.quad`. Assert integral is within 0.001 of 1.0.

12. `test_marchenko_pastur_cdf_monotone` -- Evaluate CDF at 10 evenly spaced points in the support. Assert values are non-decreasing, start near 0, end near 1.

13. `test_marchenko_pastur_cdf_boundaries` -- CDF at x <= lambda_minus should be 0.0. CDF at x >= lambda_plus should be 1.0.

14. `test_run_mp_ks_test_random_matrix` -- Generate a random matrix X from N(0,1) of shape (w, d_k) with w=64, d_k=128. Compute SVs of X @ X^T / d_k (Wishart-like). Run `run_mp_ks_test()` on the squared SVs. The KS p-value should be > 0.01 (not rejected) since the data matches MP. Use a fixed seed for reproducibility.

15. `test_run_mp_ks_test_structured_matrix` -- Create a matrix with obvious rank-1 structure (one dominant singular value). Run `run_mp_ks_test()`. The KS p-value should be < 0.05 (rejected) since the data departs from MP.

16. `test_run_mp_ks_test_returns_expected_keys` -- Verify the returned dict contains: ks_statistic, ks_p_value, gamma, sigma2, lambda_minus, lambda_plus.

**Fixture:** Create a pytest fixture `small_graph_with_jumpers` that builds a small graph (n=20, K=2, p_in=0.5, p_out=0.1) with 2 jumper vertices (one per block, r=3). Use `scipy.sparse.random` to create a directed adjacency matrix, then manually set jumper vertex info. This fixture is used by tests 1-6.

Run tests to confirm they fail (RED phase):
```bash
pytest tests/test_null_model.py -x -v 2>&1 | head -50
```
  </action>
  <verify>
    <automated>python -c "import ast; ast.parse(open('tests/test_null_model.py').read()); print('SYNTAX OK')" && pytest tests/test_null_model.py --collect-only 2>&1 | grep "test_" | wc -l</automated>
  </verify>
  <done>
    - tests/test_null_model.py exists with 16 test cases covering null walk generation (6), drift extraction (3), and MP reference (7)
    - All tests are syntactically valid and collectible by pytest
    - Tests import from src.analysis.null_model (will fail until Task 2 implements the module)
    - Test fixture provides a small reproducible graph with jumper vertices
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement null walk generator, null evaluation, drift extraction, and MP reference</name>
  <files>
    src/analysis/null_model.py
  </files>
  <action>
Create `src/analysis/null_model.py` as the standalone null analysis module. This is the GREEN phase -- implement until all tests from Task 1 pass.

**Module docstring:**
```python
"""Null model baseline: jumper-free walk generation, position-matched drift extraction,
and Marchenko-Pastur random matrix reference.

Standalone analysis module -- takes a trained model + graph and produces null analysis
independently. Can run null analysis on any existing experiment. Does NOT modify the
evaluation pipeline (per CONTEXT.md locked decision).
"""
```

**Imports needed:**
```python
import logging
import numpy as np
import torch
import torch.nn as nn
from scipy.integrate import quad
from scipy.stats import kstest

from src.config.experiment import ExperimentConfig
from src.evaluation.pipeline import EvaluationResult, fused_evaluate
from src.graph.jumpers import JumperInfo
from src.graph.types import GraphData
from src.walk.generator import generate_batch_unguided_walks
```

**Function 1: `generate_null_walks()`**

Generate walks that never visit a jumper vertex. Strategy: modify the adjacency matrix by zeroing out columns for jumper vertices (walks cannot REACH jumpers), then generate walks on the filtered graph. Handle dead-end vertices (zero out-degree after filtering) by excluding them from start vertex pool and using random restart if a walk reaches a dead end.

Implementation:
1. Build `jumper_set = {j.vertex_id for j in jumpers}`
2. Copy the adjacency matrix: `adj = graph_data.adjacency.copy().tolil()`
3. Zero out COLUMNS for jumper vertices: `adj[:, v] = 0` for each v in jumper_set. This prevents walks from reaching jumper vertices. Do NOT zero out rows -- we want the graph topology otherwise intact.
4. Convert back to CSR: `filtered_csr = adj.tocsr(); filtered_csr.eliminate_zeros()`
5. Compute out-degrees: `degrees = np.diff(filtered_csr.indptr)`. Find vertices with degree > 0 that are NOT jumpers -- these are valid start vertices.
6. If a valid start vertex set is too small (< 10), log a warning and fall back to the discard approach: generate on full graph, discard walks that visit jumpers, regenerate until count is met.
7. Generate `n_walks` walks using `generate_batch_unguided_walks()` with the filtered CSR arrays.
8. Verify: assert no walk contains a jumper vertex.

Signature:
```python
def generate_null_walks(
    graph_data: GraphData,
    jumpers: list[JumperInfo],
    config: ExperimentConfig,
    n_walks: int,
    seed: int = 9999,
) -> np.ndarray:
    """Generate walks that never encounter a jumper vertex.

    Uses column-filtered adjacency to prevent walks from reaching jumper vertices.
    Same walk length as config.training.walk_length.

    Args:
        graph_data: DCSBM graph (same graph used for training/evaluation).
        jumpers: List of JumperInfo from the experiment.
        config: ExperimentConfig for walk_length.
        n_walks: Number of null walks to generate (typically 5x violation count).
        seed: Random seed for null walk generation.

    Returns:
        Array of shape (n_walks, walk_length) with dtype int32.
    """
```

**Function 2: `run_null_evaluation()`**

Run null walks through the trained model to collect SVD metrics. This calls `fused_evaluate()` directly -- the null walks have no jumper events, so behavioral labels will show no violations (all NOT_APPLICABLE or FOLLOWED). Extract Grassmannian drift from the result.

Signature:
```python
def run_null_evaluation(
    model: nn.Module,
    null_walks: np.ndarray,
    graph_data: GraphData,
    jumpers: list[JumperInfo],
    config: ExperimentConfig,
    device: torch.device,
    batch_size: int = 32,
) -> EvaluationResult:
    """Evaluate null walks through the trained model to collect SVD metrics.

    Calls fused_evaluate() on the null walks. Since null walks contain no
    jumper vertices, all behavioral labels will be NOT_APPLICABLE.

    Args:
        model: Trained TransformerLM in eval mode.
        null_walks: Null walk array from generate_null_walks().
        graph_data: Same graph as used for training.
        jumpers: Same jumpers as the experiment (needed for fused_evaluate API).
        config: ExperimentConfig.
        device: Computation device.
        batch_size: Batch size for evaluation.

    Returns:
        EvaluationResult with SVD metrics for null walks.
    """
```
Implementation: simply call `fused_evaluate(model, null_walks, graph_data, jumpers, config, device, batch_size)` and return the result. The function exists for API clarity and future extension.

**Function 3: `extract_position_matched_drift()`**

Extract Grassmannian drift values at specific absolute positions across all sequences.

Signature:
```python
def extract_position_matched_drift(
    metric_array: np.ndarray,
    event_positions: list[int],
    max_lookback: int,
) -> dict[int, np.ndarray]:
    """Extract metric values at position-matched lookback distances.

    For each event position and each lookback j=1..max_lookback, extracts
    the metric value at position (event_position - j) across all sequences.
    Pools across all event positions.

    Args:
        metric_array: Shape [n_sequences, max_steps-1]. Metric values per step.
        event_positions: Absolute positions corresponding to violation resolution_steps.
        max_lookback: Maximum lookback distance (typically r).

    Returns:
        Dict mapping lookback distance j -> array of metric values across all
        sequences and all event positions, NaN-filtered.
    """
```
Implementation:
1. For each lookback j in 1..max_lookback:
   - For each position in event_positions:
     - idx = position - j
     - If 0 <= idx < metric_array.shape[1]: extract metric_array[:, idx]
   - Concatenate all extracted values, filter NaN
   - Store in result dict keyed by j

**Function 4: `marchenko_pastur_pdf()`**

```python
def marchenko_pastur_pdf(x: float, gamma: float, sigma2: float = 1.0) -> float:
    """Marchenko-Pastur probability density function.

    For the distribution of eigenvalues of (1/n) X^T X where X is m x n
    with iid entries of variance sigma^2 and gamma = m/n.

    f(x) = sqrt((lam+ - x)(x - lam-)) / (2 * pi * sigma^2 * gamma * x)
    for x in [lam-, lam+], else 0.

    Args:
        x: Point at which to evaluate the PDF.
        gamma: Aspect ratio m/n.
        sigma2: Variance of the entries.

    Returns:
        PDF value at x.
    """
```
Implementation: compute lambda_plus = sigma2 * (1 + sqrt(gamma))^2, lambda_minus = sigma2 * (1 - sqrt(gamma))^2. Return 0 if x <= lambda_minus or x >= lambda_plus. Otherwise return the formula.

**Function 5: `marchenko_pastur_cdf()`**

```python
def marchenko_pastur_cdf(x: float, gamma: float, sigma2: float = 1.0) -> float:
    """Marchenko-Pastur cumulative distribution function.

    Computed by numerical integration of the PDF from lambda_minus to x.

    Args:
        x: Point at which to evaluate the CDF.
        gamma: Aspect ratio.
        sigma2: Variance parameter.

    Returns:
        CDF value at x.
    """
```
Implementation: if x <= lambda_minus return 0, if x >= lambda_plus return 1, else `quad(marchenko_pastur_pdf, lambda_minus, x, args=(gamma, sigma2))[0]`.

**Function 6: `run_mp_ks_test()`**

```python
def run_mp_ks_test(
    singular_values: np.ndarray,
    gamma: float,
) -> dict:
    """Compare empirical QK^T singular values against Marchenko-Pastur distribution.

    Calibrates sigma^2 from the mean of squared singular values using the
    MP mean formula: E[lambda] = sigma^2 * (1 + gamma), so
    sigma^2 = mean(sv^2) / (1 + gamma).

    Uses scipy.stats.kstest with a callable CDF.

    Args:
        singular_values: 1D array of empirical singular values from QK^T.
        gamma: Aspect ratio w / d_model.

    Returns:
        Dict with: ks_statistic, ks_p_value, gamma, sigma2, lambda_minus, lambda_plus.
    """
```
Implementation: compute sv_squared = singular_values ** 2. Calibrate sigma2 = mean(sv_squared) / (1 + gamma). Run kstest(sv_squared, lambda x: marchenko_pastur_cdf(x, gamma, sigma2)). Return dict with all fields.

After implementing all functions, run tests:
```bash
pytest tests/test_null_model.py -x -v
```

All 16 tests must pass (GREEN phase).
  </action>
  <verify>
    <automated>pytest tests/test_null_model.py -x -v</automated>
  </verify>
  <done>
    - All 16 tests pass
    - generate_null_walks() produces jumper-free walks on filtered adjacency, correct count, valid edges, deterministic
    - extract_position_matched_drift() correctly extracts values at event positions minus lookback, filters NaN
    - marchenko_pastur_pdf() has correct support bounds and integrates to 1
    - marchenko_pastur_cdf() is monotone with correct boundary values
    - run_mp_ks_test() accepts random matrix data (high p-value) and rejects structured data (low p-value)
    - Module is standalone (does not modify evaluation pipeline)
  </done>
</task>

</tasks>

<verification>
```bash
# All null model tests pass
pytest tests/test_null_model.py -x -v

# Module is importable with all expected exports
python -c "from src.analysis.null_model import generate_null_walks, run_null_evaluation, extract_position_matched_drift, marchenko_pastur_pdf, marchenko_pastur_cdf, run_mp_ks_test; print('All exports OK')"

# No regressions in existing tests
pytest tests/ -x --timeout=120

# MP PDF integrates to 1
python -c "
from scipy.integrate import quad
from src.analysis.null_model import marchenko_pastur_pdf
import numpy as np
gamma = 0.5
lam_minus = (1 - np.sqrt(gamma))**2
lam_plus = (1 + np.sqrt(gamma))**2
result, _ = quad(marchenko_pastur_pdf, lam_minus, lam_plus, args=(gamma, 1.0))
assert abs(result - 1.0) < 0.001, f'MP PDF integral = {result}, expected 1.0'
print(f'MP PDF integral = {result:.6f} -- OK')
"
```
</verification>

<success_criteria>
- Standalone `src/analysis/null_model.py` module with 6 exported functions
- Null walk generator produces jumper-free walks using column-filtered adjacency
- Position-matched drift extraction correctly aligns null and violation distributions
- Marchenko-Pastur PDF/CDF are mathematically correct (integrates to 1, correct support)
- KS test wrapper correctly compares empirical SVs against MP with data-calibrated sigma2
- All 16 tests pass; no regressions in existing test suite
- Module does not modify evaluation pipeline (standalone per CONTEXT.md decision)
</success_criteria>

<output>
After completion, create `.planning/phases/12-null-model-baseline/12-01-SUMMARY.md`
</output>
