---
phase: 14-softmax-filtering-bound
plan: 02
type: execute
wave: 2
depends_on: [14-01]
files_modified:
  - src/analysis/perturbation_bound.py
  - src/visualization/perturbation_bound.py
  - src/visualization/render.py
  - src/reporting/single.py
  - src/reporting/templates/single_report.html
  - src/results/schema.py
  - tests/test_perturbation_bound.py
autonomous: true
requirements: [SFTX-02, SFTX-03]

must_haves:
  truths:
    - "inject_perturbation computes perturbed AVWo by injecting a controlled perturbation into QK^T, recomputing softmax, AV, and AVWo"
    - "compute_theoretical_bound returns the theoretical bound value using ||QK^T||_F, ||V||_2, ||W_O||_2, d_k, and epsilon"
    - "run_perturbation_experiment generates both random and adversarial perturbations at each magnitude and returns per-magnitude summary statistics including violation rate"
    - "Bound tightness visualization shows theoretical envelope vs empirical measurements with tightness ratio annotated"
    - "Fewer than 5% of perturbations exceed the theoretical bound (success criterion from CONTEXT.md)"
    - "result.json perturbation_bound block validates through schema.py"
  artifacts:
    - src/analysis/perturbation_bound.py
    - src/visualization/perturbation_bound.py
    - tests/test_perturbation_bound.py
  key_links:
    - "perturbation_bound.py reuses _compute_avwo_for_layer pattern from evaluation/pipeline.py"
    - "perturbation_bound.py uses torch.linalg.svdvals for measuring spectral change"
    - "render.py calls plot_bound_tightness and saves perturbation_bound_* figures"
    - "single.py collects perturbation_bound_* figures and passes to template"
    - "single_report.html renders Softmax Bound section as collapsible details/summary block"
---

<objective>
Implement controlled perturbation experiments to empirically verify the softmax filtering bound, with bound tightness visualization and HTML report integration.

Purpose: SFTX-02 requires empirical verification by injecting controlled perturbations and checking fewer than 5% exceed the bound. SFTX-03 requires visualization with tightness ratio.
Output: Perturbation experiment module, visualization, report integration, schema validation, and tests.
</objective>

<execution_context>
@/root/.claude/get-shit-done/workflows/execute-plan.md
@/root/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/14-softmax-filtering-bound/14-CONTEXT.md
@.planning/phases/14-softmax-filtering-bound/14-RESEARCH.md
@.planning/phases/14-softmax-filtering-bound/14-01-PLAN.md

@src/model/attention.py
@src/model/transformer.py
@src/evaluation/pipeline.py
@src/evaluation/svd_metrics.py
@src/visualization/style.py
@src/visualization/render.py
@src/reporting/single.py
@src/reporting/templates/single_report.html
@src/results/schema.py

<interfaces>
<!-- Key types and contracts the executor needs. -->

From src/model/attention.py:
```python
class CausalSelfAttention(nn.Module):
    def __init__(self, d_model: int, max_seq_len: int, dropout: float = 0.0):
        self.W_q = nn.Linear(d_model, d_model, bias=False)
        self.W_k = nn.Linear(d_model, d_model, bias=False)
        self.W_v = nn.Linear(d_model, d_model, bias=False)
        self.W_o = nn.Linear(d_model, d_model, bias=False)

    def forward(self, x, extract=False) -> tuple[Tensor, AttentionInternals | None]:
        # Q = W_q(x), K = W_k(x), V = W_v(x)
        # qkt_raw = (Q @ K^T) * (1/sqrt(d_model))
        # A = softmax(masked(qkt_raw))
        # y = W_o(A @ V)
```

From src/model/transformer.py:
```python
class TransformerLM(nn.Module):
    self.blocks: nn.ModuleList  # list of TransformerBlock
    def forward(self, idx, mode=ExtractionMode.NONE) -> ForwardOutput:
        # ForwardOutput has: logits, qkt, attention_weights, values
    def get_wvwo(self) -> Tensor:  # [n_layers, D, D]
```

From src/evaluation/pipeline.py:
```python
def _compute_avwo_for_layer(attention_weights, values, model, layer_idx):
    AV = attention_weights @ values  # [B, T, D]
    Wo = model.blocks[layer_idx].attention.W_o.weight  # [D, D]
    return AV @ Wo.T  # [B, T, D]
```

From src/model/types.py:
```python
@dataclass
class ForwardOutput:
    logits: Tensor
    qkt: Tensor | None        # [B, n_layers, T, T]
    attention_weights: Tensor | None  # [B, n_layers, T, T]
    values: Tensor | None     # [B, n_layers, T, D]
```

From src/visualization/style.py:
```python
PALETTE = sns.color_palette("colorblind", n_colors=8)
VIOLATION_COLOR, CONTROL_COLOR, BASELINE_COLOR, THRESHOLD_COLOR
def apply_style() -> None
def save_figure(fig, output_dir, name) -> tuple[Path, Path]
```

From src/reporting/single.py:
```python
def _collect_figures(figures_dir: Path) -> dict[str, Any]
def generate_single_report(result_dir, output_path=None) -> Path
```

Collapsible section pattern from Phase 13:
```html
<details class="enrichment-section">
  <summary><strong>Section Title</strong></summary>
  <div class="section-content">...</div>
</details>
```
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create perturbation experiment module and tests</name>
  <files>
    src/analysis/perturbation_bound.py
    tests/test_perturbation_bound.py
  </files>
  <action>
Create `src/analysis/perturbation_bound.py`:

1. **`compute_theoretical_bound`:** Compute the theoretical bound value.
   - Args: qkt_fro_norm (float), v_spectral_norm (float), wo_spectral_norm (float), d_k (int), epsilon (float)
   - Return: epsilon * qkt_fro_norm * v_spectral_norm * wo_spectral_norm / (2.0 * math.sqrt(d_k))
   - This is the bound from Theorem 6.1 of the derivation

2. **`inject_perturbation`:** Apply a perturbation to QK^T and recompute AVWo.
   - Args: qkt (Tensor [T, T]), values (Tensor [T, D]), wo_weight (Tensor [D, D]), d_model (int), perturbation (Tensor [T, T]), causal_mask (Tensor [T, T] bool)
   - Steps:
     a. Scale: scale = 1.0 / math.sqrt(d_model)
     b. Perturbed QK^T: qkt_perturbed = qkt + perturbation (both already scaled by 1/sqrt(d_k) from the forward pass)
     c. Apply causal mask: qkt_perturbed = qkt_perturbed.masked_fill(~causal_mask, float('-inf'))
     d. Attention: A_perturbed = F.softmax(qkt_perturbed, dim=-1)
     e. AV: av_perturbed = A_perturbed @ values
     f. AVWo: avwo_perturbed = av_perturbed @ wo_weight.T
   - Return: avwo_perturbed (Tensor [T, D])
   - NOTE: The qkt passed from ForwardOutput is already scaled by 1/sqrt(d_model), so the perturbation must also be in the scaled space.

3. **`compute_spectral_change`:** Measure the spectral change between original and perturbed AVWo.
   - Args: avwo_original (Tensor), avwo_perturbed (Tensor)
   - Compute: sigma_orig = torch.linalg.svdvals(avwo_original), sigma_pert = torch.linalg.svdvals(avwo_perturbed)
   - Return: float -- ||sigma_pert - sigma_orig||_2 (L2 norm of singular value difference vector)

4. **`generate_adversarial_direction`:** Generate adversarial perturbation direction.
   - Args: qkt (Tensor [T, T]), causal_mask (Tensor [T, T] bool)
   - Compute SVD of qkt (masked to lower triangle): U, S, Vh = torch.linalg.svd(qkt.masked_fill(~causal_mask, 0.0))
   - Adversarial direction: u_1 @ v_1^T (rank-1 outer product from top singular vectors)
   - Apply causal mask to direction: zero out upper triangle
   - Normalize to unit Frobenius norm
   - Return: direction (Tensor [T, T])

5. **`generate_random_direction`:** Generate random perturbation direction.
   - Args: T (int), causal_mask (Tensor [T, T] bool), generator (torch.Generator)
   - Generate random Tensor [T, T] from standard normal
   - Apply causal mask: zero out upper triangle
   - Normalize to unit Frobenius norm
   - Return: direction (Tensor [T, T])

6. **`run_perturbation_at_step`:** Run perturbation experiment at a single step.
   - Args: model (nn.Module), input_ids (Tensor [1, T]), layer_idx (int), magnitudes (list[float]), n_random (int), seed (int)
   - Forward pass with extraction: output = model(input_ids, mode=ExtractionMode.SVD_TARGETS)
   - Extract: qkt = output.qkt[0, layer_idx] (already scaled), V = output.values[0, layer_idx], W_o = model.blocks[layer_idx].attention.W_o.weight
   - Compute d_model from model
   - Build causal mask: lower triangular [T, T]
   - Compute original AVWo via inject_perturbation with zero perturbation (or directly: A_orig = output.attention_weights[0, layer_idx], AV = A_orig @ V, AVWo_orig = AV @ W_o.T)
   - Compute norms: ||QK^T||_F (of the scaled qkt, for the theoretical bound we need ||QK^T_unscaled||_F = ||qkt|| * sqrt(d_model)), ||V||_2 = sigma_1(V), ||W_o||_2 = sigma_1(W_o)
   - NOTE on scaling: Since qkt from the model is already QK^T/sqrt(d_k), the Frobenius norm we need for the theoretical bound formula is ||QK^T||_F = ||qkt_raw||_F * sqrt(d_k) where qkt_raw is the unscaled version. But epsilon is defined as ||Delta QK^T||_F / ||QK^T||_F. When we perturb the scaled qkt, we need: perturbation_scaled = epsilon * ||qkt_scaled||_F * direction. The theoretical bound becomes: epsilon * ||qkt_scaled||_F * sqrt(d_k) * ||V||_2 * ||W_o||_2 / (2 * sqrt(d_k)) = epsilon * ||qkt_scaled||_F * ||V||_2 * ||W_o||_2 / 2. The sqrt(d_k) factors cancel because we measure epsilon relative to the SCALED matrix.
   - For EACH magnitude epsilon:
     a. Theoretical bound = epsilon * qkt_fro * v_spec * wo_spec / 2.0 (after cancellation)
     b. Adversarial: perturbation = epsilon * qkt_fro * adversarial_direction. Compute spectral change. Record ratio = change / bound.
     c. Random (n_random directions): for each, perturbation = epsilon * qkt_fro * random_direction. Compute spectral change. Record ratio.
   - Return: dict per magnitude with adversarial and random results

7. **`run_perturbation_experiment`:** Top-level orchestrator.
   - Args: model (nn.Module), eval_walks (np.ndarray), config (ExperimentConfig), device (torch.device), layer_idx (int = 0), magnitudes (list[float] = [0.01, 0.05, 0.10, 0.25]), n_random (int = 20), n_steps (int = 50), seed (int = 42)
   - Select n_steps uniformly spaced step positions from eval_walks (positions >= w)
   - For each step: run_perturbation_at_step
   - Aggregate across steps:
     - Per magnitude, per direction type (adversarial, random):
       - mean_ratio: mean of (actual_change / theoretical_bound)
       - max_ratio: max of (actual_change / theoretical_bound)
       - n_exceeding_bound: count where ratio > 1.0
       - n_total: total experiments
   - Compute overall tightness_ratio: median of all ratios across all magnitudes and directions
   - Compute overall violation_rate: total n_exceeding / total n_total
   - Return dict:
     ```python
     {
         "config": {
             "magnitudes": magnitudes,
             "n_random_directions": n_random,
             "n_steps": n_steps,
             "layer_idx": layer_idx,
             "seed": seed,
             "d_model": d_model,
         },
         "theoretical_bound_formula": "epsilon * ||QK^T||_F * ||V||_2 * ||W_O||_2 / (2 * sqrt(d_k))",
         "by_magnitude": {
             str(eps): {
                 "adversarial": {
                     "mean_ratio": float,
                     "max_ratio": float,
                     "n_exceeding_bound": int,
                     "n_total": int,
                 },
                 "random": {
                     "mean_ratio": float,
                     "max_ratio": float,
                     "n_exceeding_bound": int,
                     "n_total": int,
                 },
                 "theoretical_bound_value_mean": float,  # mean bound value across steps
             }
         },
         "tightness_ratio": float,
         "violation_rate": float,
         "bound_verified": bool,  # True if violation_rate < 0.05
     }
     ```

Create `tests/test_perturbation_bound.py`:

1. **test_compute_theoretical_bound:** Known values: qkt_fro=10.0, v_spec=5.0, wo_spec=3.0, d_k=64, eps=0.1. Expected: 0.1 * 10 * 5 * 3 / (2 * 8) = 0.9375. Verify close match.

2. **test_inject_perturbation_zero:** Zero perturbation should give identical AVWo (within floating point). Build a small model (d_model=16, seq_len=8), forward pass, inject zero perturbation. Verify spectral change ~0.

3. **test_inject_perturbation_nonzero:** Non-zero perturbation should give non-zero spectral change. Build same small model, inject random perturbation. Verify spectral change > 0.

4. **test_adversarial_direction_unit_norm:** Generate adversarial direction from random QK^T. Verify Frobenius norm is 1.0 (within tolerance). Verify upper triangle is zero (causal mask).

5. **test_random_direction_unit_norm:** Generate random direction. Verify Frobenius norm is 1.0. Verify upper triangle is zero.

6. **test_bound_holds_small_model:** Create a small TransformerLM (d_model=16, n_layers=1, vocab=20, max_seq=8). Generate a random input sequence. Run run_perturbation_at_step with magnitudes=[0.01, 0.10, 0.25], n_random=10. Verify that NO perturbation exceeds the theoretical bound (ratio <= 1.0 for all).

7. **test_adversarial_larger_than_random:** At the same magnitude, adversarial perturbation should produce larger spectral change than average random. Run experiment and verify adversarial mean_ratio > mean of random mean_ratios (at least at one magnitude).

8. **test_run_perturbation_experiment_structure:** Create minimal model and walks. Run run_perturbation_experiment with small parameters (n_steps=3, n_random=5, magnitudes=[0.05]). Verify output dict has correct structure: config, by_magnitude, tightness_ratio, violation_rate, bound_verified keys.

Use `torch.manual_seed` for reproducibility. All tests should work on CPU.
  </action>
  <verify>
    <automated>cd /root/Repos/dcsbm-transformer && python -m pytest tests/test_perturbation_bound.py -x -v</automated>
  </verify>
  <done>
    - compute_theoretical_bound returns correct value for known inputs
    - inject_perturbation with zero perturbation gives near-zero spectral change
    - Adversarial and random directions are unit-norm with correct causal masking
    - Bound holds on small model (no perturbation exceeds theoretical bound)
    - Adversarial perturbations produce larger spectral change than random on average
    - run_perturbation_experiment returns correctly structured output dict
    - All tests pass
  </done>
</task>

<task type="auto">
  <name>Task 2: Create bound tightness visualization and integrate into render pipeline and HTML report</name>
  <files>
    src/visualization/perturbation_bound.py
    src/visualization/render.py
    src/reporting/single.py
    src/reporting/templates/single_report.html
    src/results/schema.py
  </files>
  <action>
**Create `src/visualization/perturbation_bound.py`:**

1. **`plot_bound_tightness`:** Main bound tightness visualization.
   - Args: perturbation_results (dict from run_perturbation_experiment)
   - Create figure with 1 row, 1 column (or 1x2 if separate random vs adversarial)
   - X-axis: perturbation magnitude (epsilon)
   - Y-axis: ratio = actual spectral change / theoretical bound
   - For each magnitude:
     - Plot adversarial results as red/orange scatter points (one per step) or box/violin
     - Plot random results as blue scatter points (multiple per step)
     - Plot theoretical bound as horizontal dashed line at ratio = 1.0 (anything above this line exceeds the bound)
   - Add shaded region above 1.0 in light red to highlight "bound exceeded" zone
   - Annotate overall tightness ratio and violation rate
   - Title: "Softmax Filtering Bound: Empirical vs Theoretical"
   - Labels: x="Perturbation magnitude (epsilon)", y="Empirical / Theoretical bound"
   - Legend: "Adversarial", "Random", "Theoretical bound"
   - Returns plt.Figure

   Implementation approach (scatter + envelope):
   - For each magnitude, collect all ratios (adversarial and random)
   - Plot scatter with low alpha for random (blue, alpha=0.3) and higher alpha for adversarial (red, alpha=0.7)
   - Add box plot overlay (or error bars) showing median and IQR at each magnitude
   - Theoretical bound at y=1.0 as thick dashed black line

2. **`plot_bound_by_magnitude`:** Per-magnitude detailed view.
   - Args: perturbation_results (dict)
   - Create subplots: one per magnitude value
   - Each subplot: histogram of ratios for random directions, with adversarial marked as vertical lines
   - Theoretical bound at x=1.0 as vertical dashed line
   - Returns plt.Figure

**Modify `src/visualization/render.py`:**

Add a new section after the SVD benchmark section (last enrichment section from Phase 13):

```python
# -- Perturbation Bound (SFTX-02, SFTX-03) --
perturbation_bound = result.get("metrics", {}).get("perturbation_bound", {})
if perturbation_bound and perturbation_bound.get("by_magnitude"):
    try:
        from src.visualization.perturbation_bound import (
            plot_bound_tightness,
            plot_bound_by_magnitude,
        )

        fig = plot_bound_tightness(perturbation_bound)
        paths = save_figure(fig, figures_dir, "perturbation_bound_tightness")
        generated_files.extend(paths)
        log.info("Generated: perturbation_bound_tightness")

        fig = plot_bound_by_magnitude(perturbation_bound)
        paths = save_figure(fig, figures_dir, "perturbation_bound_detail")
        generated_files.extend(paths)
        log.info("Generated: perturbation_bound_detail")

    except Exception as e:
        log.warning("Failed to generate perturbation bound plots: %s", e)
```

**Modify `src/reporting/single.py`:**

1. In `_collect_figures`, add to the result dict initialization:
   ```python
   "perturbation_bound_figures": [],
   ```
   Add handling in the for loop:
   ```python
   elif name.startswith("perturbation_bound"):
       result["perturbation_bound_figures"].append({"title": title, "data_uri": data_uri})
   ```

2. In `generate_single_report`, extract perturbation_bound data from metrics and pass to template:
   ```python
   perturbation_bound = metrics.get("perturbation_bound")
   ```
   Add to template.render() call:
   ```python
   perturbation_bound=perturbation_bound,
   perturbation_bound_figures=figures.get("perturbation_bound_figures", []),
   ```

**Modify `src/reporting/templates/single_report.html`:**

Add Softmax Bound section AFTER the SVD Cost section (or after Calibration if SVD Cost not present). This is a Phase 14 addition:

```html
<!-- Softmax Filtering Bound (SFTX-02, SFTX-03) -->
{% if perturbation_bound or perturbation_bound_figures %}
<details class="enrichment-section">
  <summary><strong>Softmax Filtering Bound</strong></summary>
  <div class="section-content">
    {% if perturbation_bound %}
    <h3>Bound Verification Summary</h3>
    <table>
      <thead>
        <tr>
          <th>Magnitude (epsilon)</th>
          <th>Direction</th>
          <th>Mean Ratio</th>
          <th>Max Ratio</th>
          <th>Exceeding Bound</th>
          <th>Total</th>
        </tr>
      </thead>
      <tbody>
        {% for eps_str, eps_data in perturbation_bound.by_magnitude|dictsort %}
        <tr>
          <td rowspan="2">{{ eps_str }}</td>
          <td>Adversarial</td>
          <td>{{ "%.4f"|format(eps_data.adversarial.mean_ratio) if eps_data.adversarial.mean_ratio is number else 'N/A' }}</td>
          <td>{{ "%.4f"|format(eps_data.adversarial.max_ratio) if eps_data.adversarial.max_ratio is number else 'N/A' }}</td>
          <td>{{ eps_data.adversarial.n_exceeding_bound }}</td>
          <td>{{ eps_data.adversarial.n_total }}</td>
        </tr>
        <tr>
          <td>Random</td>
          <td>{{ "%.4f"|format(eps_data.random.mean_ratio) if eps_data.random.mean_ratio is number else 'N/A' }}</td>
          <td>{{ "%.4f"|format(eps_data.random.max_ratio) if eps_data.random.max_ratio is number else 'N/A' }}</td>
          <td>{{ eps_data.random.n_exceeding_bound }}</td>
          <td>{{ eps_data.random.n_total }}</td>
        </tr>
        {% endfor %}
      </tbody>
    </table>

    <p>
      <strong>Tightness ratio:</strong> {{ "%.4f"|format(perturbation_bound.tightness_ratio) if perturbation_bound.tightness_ratio is number else 'N/A' }}.
      <strong>Violation rate:</strong> {{ "%.4f"|format(perturbation_bound.violation_rate) if perturbation_bound.violation_rate is number else 'N/A' }}.
      <strong>Bound verified:</strong> {{ "Yes" if perturbation_bound.bound_verified else "No" }}.
    </p>
    {% endif %}

    {% if perturbation_bound_figures %}
    <h3>Bound Tightness Plots</h3>
    {% for fig in perturbation_bound_figures %}
    <div class="figure-container">
      <div class="figure-title">{{ fig.title }}</div>
      <img src="{{ fig.data_uri }}" alt="{{ fig.title }}">
    </div>
    {% endfor %}
    {% endif %}
  </div>
</details>
{% endif %}
```

**Modify `src/results/schema.py`:**

Add optional perturbation_bound validation block (backward-compatible):

```python
# Optional perturbation_bound validation (Phase 14, backward compatible)
if "metrics" in result and isinstance(result["metrics"], dict):
    pb = result["metrics"].get("perturbation_bound")
    if pb is not None:
        if not isinstance(pb, dict):
            errors.append("metrics.perturbation_bound must be a dict")
        else:
            if "by_magnitude" not in pb:
                errors.append("metrics.perturbation_bound missing required block: by_magnitude")
            for field in ["tightness_ratio", "violation_rate", "bound_verified"]:
                if field not in pb:
                    errors.append(f"metrics.perturbation_bound missing field: {field}")
```
  </action>
  <verify>
    <automated>cd /root/Repos/dcsbm-transformer && python -m pytest tests/test_perturbation_bound.py tests/test_reporting.py -x -v</automated>
  </verify>
  <done>
    - Bound tightness plot shows scatter of empirical/theoretical ratios with bound line at 1.0
    - Per-magnitude detail plot shows histogram of ratios per direction type
    - render.py generates perturbation_bound_* figures when bound data exists in result.json
    - single.py collects perturbation_bound_* figures and passes to template
    - HTML template renders Softmax Bound section as collapsible block with verification summary table
    - schema.py validates perturbation_bound block when present, passes when absent (backward compatible)
    - All existing tests still pass
  </done>
</task>

</tasks>

<verification>
- `pytest tests/test_perturbation_bound.py -x -v` passes all perturbation bound tests
- `pytest tests/test_reporting.py -x -v` passes (existing + new bound section)
- `pytest tests/ -x` full suite passes (no regressions)
- Perturbation experiments confirm bound holds (violation_rate < 0.05)
- Tightness ratio is reported and meaningful (typically 0.1-0.5)
- HTML report renders collapsible Softmax Bound section
</verification>

<success_criteria>
- SFTX-02: Bound empirically verified with fewer than 5% violations across random and adversarial perturbations
- SFTX-03: Bound tightness visualization shows theoretical envelope vs empirical measurements, tightness ratio reported
- Schema validates perturbation_bound block in result.json
- All tests pass including existing suite
</success_criteria>

<output>
After completion, create `.planning/phases/14-softmax-filtering-bound/14-02-SUMMARY.md`
</output>
