---
phase: 16-multi-head-ablation
plan: 02
type: execute
wave: 2
depends_on: [16-01]
files_modified:
  - src/evaluation/pipeline.py
  - tests/test_evaluation_pipeline.py
autonomous: true
requirements: [MHAD-02]
---

must_haves:
  truths:
    - "fused_evaluate iterates over heads within each layer for QK^T SVD, computing per-head metrics"
    - "SVD metric keys follow format target.layer_N.head_H.metric_name (e.g., qkt.layer_0.head_0.grassmannian_distance)"
    - "When n_heads=1, BOTH legacy v1.0 keys (target.layer_N.metric_name) AND v1.1 per-head keys (target.layer_N.head_0.metric_name) are emitted"
    - "When n_heads>1, only v1.1 per-head keys are emitted (no legacy format)"
    - "_compute_avwo_for_layer handles per-head attention weights and values correctly"
    - "Per-head Grassmannian distance is tracked per (target, layer, head) tuple"
    - "WvWo metrics are computed per-head with the correct per-head OV circuit matrix"
    - "Spectrum trajectory storage includes head dimension: keys like qkt.layer_N.head_H.spectrum"
    - "EvaluationResult.svd_metrics contains per-head keys"
    - "save_evaluation_results correctly saves all per-head metric arrays to NPZ"
    - "All existing pipeline tests pass with n_heads=1 configuration"
  artifacts:
    - src/evaluation/pipeline.py
    - tests/test_evaluation_pipeline.py
  key_links:
    - "fused_evaluate reads n_heads from config.model.n_heads"
    - "SVD collection loop is: for layer_idx -> for head_idx -> compute SVD on qkt[:, layer_idx, head_idx]"
    - "Dual key emission conditional: if n_heads == 1, emit both legacy and per-head keys"
    - "_compute_avwo_for_layer takes head_idx parameter and uses per-head attention weights and values"
    - "Grassmannian u_prev dict keyed by (target, layer_idx, head_idx) instead of (target, layer_idx)"
    - "get_wvwo returns [n_layers, n_heads, d_model, d_model], indexed per head in WvWo metric loop"

<objective>
Update the evaluation pipeline to compute per-head SVD metrics with dual key emission for backward compatibility.

Purpose: MHAD-02 requires SVD metrics computed per-head with NPZ keys in format `target.layer_N.head_H.metric_name`, with backward-compatible dual key emission for single-head runs.
Output: Modified evaluation pipeline with per-head SVD collection, updated key format, and comprehensive tests.
</objective>

<execution_context>
@/root/.claude/get-shit-done/workflows/execute-plan.md
@/root/.claude/get-shit-done/references/tdd.md
@/root/.claude/get-shit-done/references/checkpoints.md
@/root/.claude/get-shit-done/references/model-profile-resolution.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/16-multi-head-ablation/16-CONTEXT.md
@.planning/phases/16-multi-head-ablation/16-RESEARCH.md

@src/evaluation/pipeline.py
@src/evaluation/svd_metrics.py
@src/model/transformer.py
@src/model/types.py
@tests/test_evaluation_pipeline.py

<interfaces>
<!-- Key types and contracts the executor needs. -->

After Plan 16-01, the model produces:
```python
# ForwardOutput shapes (multi-head):
output.qkt              # [B, n_layers, n_heads, T, T]
output.attention_weights # [B, n_layers, n_heads, T, T]
output.values           # [B, n_layers, n_heads, T, d_head]

# get_wvwo() returns:
wvwo                    # [n_layers, n_heads, d_model, d_model]
```

Current fused_evaluate SVD collection structure (L260-378):
```python
for layer_idx in range(n_layers):
    qkt_matrix = output.qkt[:, layer_idx]  # Currently [B, T, T]
    # SVD on qkt_matrix...
    key = f"qkt.layer_{layer_idx}.{metric_name}"
    # ...
    A_layer = output.attention_weights[:, layer_idx]  # [B, T, T]
    V_layer = output.values[:, layer_idx]  # [B, T, D]
    avwo_matrix = _compute_avwo_for_layer(A_layer, V_layer, model, layer_idx)
```

After changes, must become:
```python
for layer_idx in range(n_layers):
    for head_idx in range(n_heads):
        qkt_matrix = output.qkt[:, layer_idx, head_idx]  # [B, T, T]
        key = f"qkt.layer_{layer_idx}.head_{head_idx}.{metric_name}"
        if n_heads == 1:
            legacy_key = f"qkt.layer_{layer_idx}.{metric_name}"
        # ...
```

Current _compute_avwo_for_layer signature:
```python
def _compute_avwo_for_layer(attention_weights, values, model, layer_idx):
    AV = attention_weights @ values  # [B, T, D]
    Wo = model.blocks[layer_idx].attention.W_o.weight  # [D, D]
    return AV @ Wo.T
```

Must change to handle per-head:
```python
def _compute_avwo_for_layer(attention_weights, values, model, layer_idx, head_idx):
    # attention_weights: [B, T, T] (per-head)
    # values: [B, T, d_head] (per-head)
    AV = attention_weights @ values  # [B, T, d_head]
    Wo = model.blocks[layer_idx].attention.W_o.weight  # [d_model, d_model]
    d_head = values.shape[-1]
    start = head_idx * d_head
    end = (head_idx + 1) * d_head
    Wo_h = Wo[:, start:end]  # [d_model, d_head]
    return AV @ Wo_h.T  # [B, T, d_model]
```
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Update _compute_avwo_for_layer for per-head computation</name>
  <files>
    src/evaluation/pipeline.py
  </files>
  <action>
Update the `_compute_avwo_for_layer` function to accept head_idx and compute per-head AVWo:

```python
def _compute_avwo_for_layer(
    attention_weights: torch.Tensor,
    values: torch.Tensor,
    model: nn.Module,
    layer_idx: int,
    head_idx: int = 0,
    n_heads: int = 1,
) -> torch.Tensor:
    """Compute AVWo (net residual update) for a single layer and head.

    For multi-head: AVWo_h = (A_h @ V_h) @ W_o_h^T where W_o_h is the
    slice of W_o that maps head h's output back to the residual stream.

    Args:
        attention_weights: Per-head attention weights, shape [B, T, T].
        values: Per-head value matrix, shape [B, T, d_head].
        model: TransformerLM model (for accessing W_o weights).
        layer_idx: Index of the transformer block.
        head_idx: Index of the attention head (0 for single-head).
        n_heads: Total number of heads.

    Returns:
        Per-head AVWo tensor of shape [B, T, d_model].
    """
    AV = attention_weights @ values  # [B, T, d_head]
    Wo = model.blocks[layer_idx].attention.W_o.weight  # [d_model, d_model]

    if n_heads == 1:
        # Single-head: same as v1.0 -- AV is [B, T, d_model], Wo is [d_model, d_model]
        return AV @ Wo.T
    else:
        # Multi-head: slice W_o for this head
        d_head = values.shape[-1]
        start = head_idx * d_head
        end = (head_idx + 1) * d_head
        Wo_h = Wo[:, start:end]  # [d_model, d_head]
        return AV @ Wo_h.T  # [B, T, d_model]
```
  </action>
</task>

<task type="auto">
  <name>Task 2: Update fused_evaluate for per-head SVD collection</name>
  <files>
    src/evaluation/pipeline.py
  </files>
  <action>
Modify fused_evaluate to iterate over heads. Key changes:

1. **Read n_heads from config:**
```python
n_heads = config.model.n_heads
```

2. **Update WvWo pre-computation to iterate over heads:**
```python
wvwo_layer_metrics: dict[tuple[int, int], dict[str, float]] = {}  # (layer, head) -> metrics

for layer_idx in range(n_layers):
    for head_idx in range(n_heads):
        wvwo_matrix = wvwo[layer_idx, head_idx]  # [d_model, d_model]
        wvwo_clean, guard_fired = guard_matrix_for_svd(wvwo_matrix)
        guard_key = f"wvwo.layer_{layer_idx}.head_{head_idx}"
        if n_heads == 1:
            guard_activations[f"wvwo.layer_{layer_idx}"] = 1 if guard_fired else 0
        guard_activations[guard_key] = 1 if guard_fired else 0

        U, S, Vh = torch.linalg.svd(wvwo_clean, full_matrices=False)
        metrics = compute_all_metrics(S, U=U, Vh=Vh)
        wvwo_layer_metrics[(layer_idx, head_idx)] = {
            k: v.item() if v.dim() == 0 else v.cpu().numpy()
            for k, v in metrics.items()
        }
```

3. **Update SVD metric key allocation to include head dimension:**
```python
svd_metric_arrays: dict[str, np.ndarray] = {}

for target in SVD_TARGETS:
    for layer_idx in range(n_layers):
        for head_idx in range(n_heads):
            for metric_name in all_metric_names:
                # v1.1 per-head key (always emitted)
                key = f"{target}.layer_{layer_idx}.head_{head_idx}.{metric_name}"
                svd_metric_arrays[key] = np.full(
                    (n_sequences, max_steps - 1), np.nan, dtype=np.float32
                )
                # Legacy v1.0 key (only for single-head)
                if n_heads == 1:
                    legacy_key = f"{target}.layer_{layer_idx}.{metric_name}"
                    svd_metric_arrays[legacy_key] = np.full(
                        (n_sequences, max_steps - 1), np.nan, dtype=np.float32
                    )
```

4. **Update Grassmannian tracking to include head index:**
```python
u_prev: dict[tuple[str, int, int], torch.Tensor | None] = {}
for target in ["qkt", "avwo"]:
    for layer_idx in range(n_layers):
        for head_idx in range(n_heads):
            u_prev[(target, layer_idx, head_idx)] = None
```

5. **Update spectrum storage to include head dimension:**
```python
spectrum_data: dict[str, np.ndarray] = {}
for target in SPECTRUM_TARGETS:
    for layer_idx in range(n_layers):
        for head_idx in range(n_heads):
            key = f"{target}.layer_{layer_idx}.head_{head_idx}.spectrum"
            spectrum_data[key] = np.full(
                (n_sequences, max_steps - 1, spectrum_k),
                np.nan, dtype=np.float16,
            )
            if n_heads == 1:
                legacy_key = f"{target}.layer_{layer_idx}.spectrum"
                spectrum_data[legacy_key] = spectrum_data[key]  # alias
```

6. **Update the inner SVD collection loop to iterate over heads:**
```python
if step >= w - 1:
    for layer_idx in range(n_layers):
        for head_idx in range(n_heads):
            # --- QK^T SVD (per-head) ---
            qkt_matrix = output.qkt[:, layer_idx, head_idx]  # [B, T, T]
            qkt_clean, qkt_guard = guard_matrix_for_svd(qkt_matrix)
            qkt_gkey = f"qkt.layer_{layer_idx}.head_{head_idx}"
            guard_activations[qkt_gkey] = (
                guard_activations.get(qkt_gkey, 0) + (1 if qkt_guard else 0)
            )

            U_qkt, S_qkt, Vh_qkt = torch.linalg.svd(qkt_clean, full_matrices=False)

            # Store spectrum trajectory
            if "qkt" in SPECTRUM_TARGETS:
                spec_key = f"qkt.layer_{layer_idx}.head_{head_idx}.spectrum"
                if spec_key in spectrum_data:
                    s_top = S_qkt[:, :spectrum_k].cpu().to(torch.float16).numpy()
                    for b_idx in range(B_actual):
                        spectrum_data[spec_key][batch_start + b_idx, step, :] = s_top[b_idx]

            qkt_metrics = compute_all_metrics(S_qkt, U=U_qkt, Vh=Vh_qkt)

            for metric_name, metric_val in qkt_metrics.items():
                key = f"qkt.layer_{layer_idx}.head_{head_idx}.{metric_name}"
                if key in svd_metric_arrays:
                    val = metric_val.mean(dim=-1) if metric_val.dim() > 1 else metric_val
                    vals_np = val.cpu().numpy()
                    for b_idx in range(B_actual):
                        svd_metric_arrays[key][batch_start + b_idx, step] = (
                            vals_np[b_idx] if vals_np.ndim > 0 else vals_np.item()
                        )
                # Dual key emission for single-head
                if n_heads == 1:
                    legacy_key = f"qkt.layer_{layer_idx}.{metric_name}"
                    if legacy_key in svd_metric_arrays:
                        val = metric_val.mean(dim=-1) if metric_val.dim() > 1 else metric_val
                        vals_np = val.cpu().numpy()
                        for b_idx in range(B_actual):
                            svd_metric_arrays[legacy_key][batch_start + b_idx, step] = (
                                vals_np[b_idx] if vals_np.ndim > 0 else vals_np.item()
                            )

            # QK^T Grassmannian distance (per-head)
            u_key = ("qkt", layer_idx, head_idx)
            U_curr_k = U_qkt[:, :, :grassmannian_k]
            if u_prev[u_key] is not None:
                gdist = grassmannian_distance(u_prev[u_key], U_curr_k, k=grassmannian_k)
                gdist_vals = gdist.mean(dim=-1) if gdist.dim() > 1 else gdist
                gdist_np = gdist_vals.cpu().numpy()
                gkey = f"qkt.layer_{layer_idx}.head_{head_idx}.grassmannian_distance"
                for b_idx in range(B_actual):
                    svd_metric_arrays[gkey][batch_start + b_idx, step] = (
                        gdist_np[b_idx] if gdist_np.ndim > 0 else gdist_np.item()
                    )
                if n_heads == 1:
                    gkey_legacy = f"qkt.layer_{layer_idx}.grassmannian_distance"
                    for b_idx in range(B_actual):
                        svd_metric_arrays[gkey_legacy][batch_start + b_idx, step] = (
                            gdist_np[b_idx] if gdist_np.ndim > 0 else gdist_np.item()
                        )
            u_prev[u_key] = U_curr_k.clone()

            # --- AVWo SVD (per-head) ---
            A_layer_head = output.attention_weights[:, layer_idx, head_idx]  # [B, T, T]
            V_layer_head = output.values[:, layer_idx, head_idx]  # [B, T, d_head]
            avwo_matrix = _compute_avwo_for_layer(
                A_layer_head, V_layer_head, model, layer_idx,
                head_idx=head_idx, n_heads=n_heads
            )  # [B, T, d_model]

            # ... (same pattern: SVD, metrics, Grassmannian, dual keys)

        # --- WvWo metrics (per-head, static, broadcast) ---
        for layer_idx in range(n_layers):
            for head_idx in range(n_heads):
                for metric_name, val in wvwo_layer_metrics[(layer_idx, head_idx)].items():
                    key = f"wvwo.layer_{layer_idx}.head_{head_idx}.{metric_name}"
                    if key in svd_metric_arrays:
                        for b_idx in range(B_actual):
                            svd_metric_arrays[key][batch_start + b_idx, step] = val
                    if n_heads == 1:
                        legacy_key = f"wvwo.layer_{layer_idx}.{metric_name}"
                        if legacy_key in svd_metric_arrays:
                            for b_idx in range(B_actual):
                                svd_metric_arrays[legacy_key][batch_start + b_idx, step] = val
```

IMPORTANT: The dual key emission pattern is:
- Always emit: `target.layer_N.head_H.metric_name`
- If n_heads == 1, also emit: `target.layer_N.metric_name` (legacy)

This ensures v1.0 analysis code works on single-head v1.1 results.
  </action>
</task>

<task type="auto">
  <name>Task 3: Update tests for per-head pipeline</name>
  <files>
    tests/test_evaluation_pipeline.py
  </files>
  <action>
Update existing evaluation pipeline tests and add new per-head tests:

1. **Update existing tests** that check SVD metric key format to handle the head dimension.
   - Tests checking for keys like `qkt.layer_0.grassmannian_distance` should still pass (legacy keys emitted for n_heads=1).

2. **Add new test: per-head key emission for single-head:**
```python
def test_single_head_dual_key_emission():
    """n_heads=1 emits both legacy and per-head keys."""
    # Run fused_evaluate with n_heads=1 config
    # Check that both 'qkt.layer_0.grassmannian_distance' and
    # 'qkt.layer_0.head_0.grassmannian_distance' exist in svd_metrics
```

3. **Add new test: per-head key emission for multi-head:**
```python
def test_multi_head_per_head_keys():
    """n_heads=2 emits per-head keys only (no legacy)."""
    # Run fused_evaluate with n_heads=2, d_model=256 config
    # Check 'qkt.layer_0.head_0.grassmannian_distance' and
    # 'qkt.layer_0.head_1.grassmannian_distance' exist
    # Check 'qkt.layer_0.grassmannian_distance' does NOT exist
```

4. **Add new test: per-head AVWo computation:**
```python
def test_per_head_avwo_shape():
    """Per-head AVWo has correct shape [B, T, d_model]."""
```

5. **Add new test: per-head WvWo metrics are distinct:**
```python
def test_per_head_wvwo_metrics_distinct():
    """Different heads have different WvWo metrics (different OV circuits)."""
```

6. **Add new test: spectrum storage includes head dimension:**
```python
def test_per_head_spectrum_keys():
    """Spectrum trajectory keys include head index."""
```

Run full test suite to verify backward compatibility:
```
pytest tests/ -x -v
```
  </action>
</task>

</tasks>
