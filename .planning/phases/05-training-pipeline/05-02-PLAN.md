---
phase: 05-training-pipeline
plan: 02
type: tdd
wave: 2
depends_on: [05-01]
files_modified:
  - src/training/checkpoint.py
  - src/training/evaluate.py
  - src/training/pipeline.py
  - src/training/__init__.py
  - tests/test_training_checkpoint.py
  - tests/test_training_evaluate.py
  - tests/test_training_pipeline.py
autonomous: true
requirements: [TRNG-03, TRNG-04, TRNG-05, TRNG-06]

must_haves:
  truths:
    - "Model weights, optimizer, scheduler, and RNG states are checkpointed every epoch with rolling retention of last 3 + gate-pass"
    - "Checkpoint resume restores all state for seamless training continuation"
    - "Greedy generation on held-out eval walks produces sequences for compliance scoring"
    - "Edge compliance measures fraction of generated edges that exist in the graph adjacency"
    - "Rule compliance measures fraction of jumper encounters where walk lands in correct target block at step+r"
    - "Training stops immediately when edge compliance >95% AND rule compliance >80%"
    - "Gate-pass result includes curves (train_loss, edge_compliance, rule_compliance) in result.json"
    - "Failed configs (gate not passed after max epochs) are flagged with failure metadata in result.json"
  artifacts:
    - path: "src/training/checkpoint.py"
      provides: "Checkpoint save, load, resume, and rolling retention"
      exports: ["save_checkpoint", "load_checkpoint", "cleanup_old_checkpoints"]
    - path: "src/training/evaluate.py"
      provides: "Greedy generation, edge compliance, rule compliance computation"
      exports: ["greedy_generate", "evaluate_compliance", "ComplianceResult"]
    - path: "src/training/pipeline.py"
      provides: "Full training pipeline orchestrating trainer, evaluator, checkpointing, gate, result writing"
      exports: ["run_training_pipeline", "TrainingPipelineResult"]
    - path: "tests/test_training_checkpoint.py"
      provides: "Tests for checkpoint save/load/resume/retention"
      min_lines: 60
    - path: "tests/test_training_evaluate.py"
      provides: "Tests for greedy generation and compliance evaluation"
      min_lines: 80
    - path: "tests/test_training_pipeline.py"
      provides: "Integration test for full pipeline with gate"
      min_lines: 40
  key_links:
    - from: "src/training/evaluate.py"
      to: "src/graph/types.py"
      via: "GraphData adjacency for edge compliance checking"
      pattern: "GraphData"
    - from: "src/training/evaluate.py"
      to: "src/graph/jumpers.py"
      via: "JumperInfo for rule compliance checking"
      pattern: "JumperInfo"
    - from: "src/training/pipeline.py"
      to: "src/results/schema.py"
      via: "write_result for persisting training outcome"
      pattern: "write_result"
    - from: "src/training/pipeline.py"
      to: "src/training/trainer.py"
      via: "Trainer for epoch-level training"
      pattern: "Trainer"
    - from: "src/training/checkpoint.py"
      to: "torch.save/torch.load"
      via: "State dict serialization"
      pattern: "torch\\.save|torch\\.load"
---

<objective>
Implement sufficiency gate evaluation, checkpoint management, and the full training pipeline that orchestrates training with early stopping on gate pass, curve logging, and result writing.

Purpose: Complete the training pipeline so the model can be trained to pass the sufficiency gate (edge compliance >95%, rule compliance >80%), with checkpointing for preemption recovery and result.json output for downstream analysis.
Output: `src/training/checkpoint.py`, `src/training/evaluate.py`, `src/training/pipeline.py` with comprehensive TDD tests.
</objective>

<execution_context>
@/root/.claude/get-shit-done/workflows/execute-plan.md
@/root/.claude/get-shit-done/references/tdd.md
@/root/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/STATE.md
@.planning/ROADMAP.md
@.planning/phases/05-training-pipeline/05-RESEARCH.md
@.planning/phases/05-training-pipeline/05-CONTEXT.md
@.planning/phases/05-training-pipeline/05-01-SUMMARY.md
@src/training/trainer.py
@src/training/data.py
@src/model/transformer.py
@src/config/experiment.py
@src/results/schema.py
@src/walk/types.py
@src/graph/types.py
@src/graph/jumpers.py
@src/reproducibility/seed.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: RED - Write failing tests for checkpoint, evaluation, and pipeline</name>
  <files>tests/test_training_checkpoint.py, tests/test_training_evaluate.py, tests/test_training_pipeline.py</files>
  <action>
Create three test files with comprehensive failing tests. Use small fixtures: tiny model (vocab=20, d_model=32, n_layers=2, max_seq_len=16), small graph (20 vertices, 4 blocks, CSR adjacency with known edges), and known jumper info.

**tests/test_training_checkpoint.py:**
- `test_save_checkpoint_creates_file`: save_checkpoint writes a .pt file to specified directory.
- `test_load_checkpoint_restores_state`: Save then load a checkpoint. Verify model state_dict, optimizer state_dict, scheduler state_dict, and epoch match.
- `test_checkpoint_includes_rng_states`: Checkpoint contains torch_rng_state, numpy_rng_state, python_rng_state.
- `test_checkpoint_includes_training_curves`: Checkpoint contains train_losses, edge_compliance_history, rule_compliance_history lists.
- `test_cleanup_old_checkpoints_keeps_last_n`: With 5 checkpoints saved, cleanup with max_keep=3 deletes oldest 2. Gate checkpoint is never deleted.
- `test_checkpoint_resume_continues_training`: Save at epoch 2, load, verify training resumes from epoch 3 with same optimizer/scheduler state.

**tests/test_training_evaluate.py:**
- `test_greedy_generate_shape`: greedy_generate returns tensor of shape [B, length].
- `test_greedy_generate_argmax`: Generated tokens are argmax of logits (verify by checking model output at each step).
- `test_evaluate_compliance_perfect_edges`: With a sequence that follows only valid edges, edge compliance is 1.0.
- `test_evaluate_compliance_invalid_edges`: With a sequence containing known invalid edges, edge compliance < 1.0 and matches expected fraction.
- `test_evaluate_compliance_rule_check`: With a sequence that hits a jumper at step t, rule compliance checks block at step t+r. Construct a known-correct and known-incorrect case.
- `test_evaluate_compliance_no_jumpers`: When no jumper vertices are encountered, rule compliance is reported as 1.0 (vacuously true — no rule checks to fail).
- `test_compliance_result_dataclass`: ComplianceResult has edge_compliance, rule_compliance, n_sequences, n_edge_checks, n_rule_checks fields.

**tests/test_training_pipeline.py:**
- `test_pipeline_returns_result`: run_training_pipeline returns TrainingPipelineResult with gate_passed, final_epoch, curves, result_path fields.
- `test_pipeline_logs_curves`: Result contains curves with train_loss (list of floats, one per step), edge_compliance (list per epoch), rule_compliance (list per epoch).
- `test_pipeline_stops_on_gate_pass`: With a rigged setup where compliance is always >95%/>80%, pipeline stops before max_epochs.
- `test_pipeline_writes_failure_metadata`: With a rigged setup where compliance never passes, pipeline runs to max_epochs and writes failure metadata.

All tests should FAIL with ImportError or similar.

Commit: `test(05-02): add failing tests for checkpoint, evaluation, and pipeline`
  </action>
  <verify>
    <automated>cd /root/Repos/dcsbm-transformer && python -m pytest tests/test_training_checkpoint.py tests/test_training_evaluate.py tests/test_training_pipeline.py -x 2>&1 | tail -5</automated>
    <manual>All tests should FAIL (RED phase)</manual>
  </verify>
  <done>Three test files exist with 15+ test functions total, all failing due to missing implementation</done>
</task>

<task type="auto">
  <name>Task 2: GREEN - Implement checkpoint, evaluation, and pipeline modules</name>
  <files>src/training/checkpoint.py, src/training/evaluate.py, src/training/pipeline.py, src/training/__init__.py</files>
  <action>
**src/training/checkpoint.py:**
- `save_checkpoint(checkpoint_dir, epoch, model, optimizer, scheduler, train_losses, edge_compliance_history, rule_compliance_history, gate_passed=False)`: Saves state dict for model, optimizer, scheduler, plus torch/numpy/python RNG states, epoch number, training curves, and gate_passed flag. File naming: `checkpoint_epoch_{epoch:04d}.pt`. If gate_passed=True, also save as `checkpoint_gate.pt`.
- `load_checkpoint(checkpoint_path, model, optimizer, scheduler, device)`: Loads checkpoint and restores all state: model.load_state_dict, optimizer.load_state_dict, scheduler.load_state_dict, torch RNG state, numpy RNG state, python RNG state. Returns dict with epoch, train_losses, edge_compliance_history, rule_compliance_history, gate_passed.
- `cleanup_old_checkpoints(checkpoint_dir, max_keep=3)`: Glob for `checkpoint_epoch_*.pt`, sort by name, delete all but last max_keep. Never delete `checkpoint_gate.pt`.
- `find_latest_checkpoint(checkpoint_dir) -> Path | None`: Find the most recent epoch checkpoint for auto-resume.

**src/training/evaluate.py:**
- `@dataclass ComplianceResult`: edge_compliance (float), rule_compliance (float), n_sequences (int), n_edge_checks (int), n_rule_checks (int).
- `greedy_generate(model, start_tokens, length, max_seq_len, device) -> torch.Tensor`: Generate sequences via argmax decoding. start_tokens is [B, 1]. For each step, forward pass on last max_seq_len tokens, take argmax of logits[:, -1, :], append. Returns [B, length]. Uses torch.no_grad() and model.eval().
- `evaluate_compliance(model, eval_walks, graph_data, jumpers, config, device, n_sequences=1000) -> ComplianceResult`:
  1. Select first n_sequences eval walks (or all if fewer).
  2. Extract first token of each selected walk as seed.
  3. Call greedy_generate with walk_length from config.
  4. For each generated sequence, check:
     - Edge compliance: for each consecutive pair (u, v), check if edge u->v exists in graph_data.adjacency (CSR lookup).
     - Rule compliance: for each step t, if token at step t is a jumper vertex, check if token at step t+r is in the jumper's target block (via graph_data.block_assignments). Use config.training.r for jump length.
  5. Return ComplianceResult with fractions. If no rule checks possible (no jumpers encountered), report rule_compliance=1.0.

**src/training/pipeline.py:**
- `@dataclass TrainingPipelineResult`: gate_passed (bool), final_epoch (int), curves (dict with keys train_loss, edge_compliance, rule_compliance), result_path (str | None), failure_reason (str | None).
- `run_training_pipeline(model, train_walks, eval_walks, graph_data, jumpers, config, device, results_dir="results", max_epochs=50, resume_from=None) -> TrainingPipelineResult`:
  1. Create WalkDataset and DataLoader from train_walks.
  2. Create Trainer with model and config.
  3. Compute total_steps = max_epochs * len(dataloader). Update trainer's scheduler T_max.
  4. If resume_from, load checkpoint and restore state.
  5. Loop epochs from start_epoch to max_epochs:
     a. `epoch_losses = trainer.train_epoch(dataloader)` — accumulate all per-step losses.
     b. Evaluate compliance: `result = evaluate_compliance(model, eval_walks, graph_data, jumpers, config, device)`.
     c. Log epoch summary to console: `Epoch {N}: loss={avg:.4f}, edge={edge:.3f}, rule={rule:.3f}`.
     d. Save checkpoint with rolling retention (keep last 3 + gate).
     e. Gate check: if edge_compliance > 0.95 and rule_compliance > 0.80, save gate checkpoint, set gate_passed=True, break.
  6. Build curves dict: train_loss = flat list of all per-step losses, edge_compliance = per-epoch list, rule_compliance = per-epoch list.
  7. Write result.json via write_result:
     - metrics.scalars: final_train_loss, final_edge_compliance, final_rule_compliance, gate_passed, epochs_trained.
     - metrics.curves: train_loss, edge_compliance, rule_compliance.
     - If gate not passed: metadata includes gate_passed=False, failure_reason="Sufficiency gate not passed after {N} epochs", final_edge_compliance, final_rule_compliance.
  8. Return TrainingPipelineResult.

**Update src/training/__init__.py:**
Add exports: save_checkpoint, load_checkpoint, cleanup_old_checkpoints, find_latest_checkpoint, greedy_generate, evaluate_compliance, ComplianceResult, run_training_pipeline, TrainingPipelineResult.

Commit: `feat(05-02): implement checkpoint management, compliance evaluation, and training pipeline`
  </action>
  <verify>
    <automated>cd /root/Repos/dcsbm-transformer && python -m pytest tests/test_training_checkpoint.py tests/test_training_evaluate.py tests/test_training_pipeline.py -x -v</automated>
    <manual>All tests pass (GREEN phase)</manual>
  </verify>
  <done>All tests pass. Checkpoints save/load with full state including RNG. Greedy generation produces argmax sequences. Compliance evaluation correctly checks edges and rules. Pipeline stops on gate pass and writes result.json with curves and failure metadata.</done>
</task>

<task type="auto">
  <name>Task 3: Verify full test suite passes with no regressions</name>
  <files>tests/test_training.py, tests/test_training_checkpoint.py, tests/test_training_evaluate.py, tests/test_training_pipeline.py</files>
  <action>
Run the complete test suite to confirm no regressions across all project tests. Fix any issues found.

Also verify:
1. `python -c "from src.training import run_training_pipeline, Trainer, evaluate_compliance"` imports cleanly.
2. All public exports from src/training/__init__.py resolve correctly.
3. Cross-check that the pipeline's result.json output passes validate_result from src/results/schema.py.

If any test fails, fix the implementation to make it pass. Do NOT weaken tests.

Commit (if fixes needed): `fix(05-02): resolve test suite regressions`
  </action>
  <verify>
    <automated>cd /root/Repos/dcsbm-transformer && python -m pytest tests/ -x -v</automated>
    <manual>Full test suite passes with zero failures</manual>
  </verify>
  <done>All tests pass across the entire project. No regressions from Phase 5 implementation.</done>
</task>

</tasks>

<verification>
- `python -m pytest tests/test_training_checkpoint.py tests/test_training_evaluate.py tests/test_training_pipeline.py -v` — all new tests pass
- `python -m pytest tests/ -x` — full test suite passes
- Checkpoint save/load round-trips correctly with RNG state
- Rolling retention keeps exactly 3 + gate checkpoint
- Greedy generation produces valid tensor output
- Edge and rule compliance return correct fractions on known data
- Pipeline stops on gate pass before max_epochs (with rigged compliance)
- Pipeline writes failure metadata when gate fails after max_epochs
- result.json validates against project schema
</verification>

<success_criteria>
- src/training/checkpoint.py: save, load, resume, rolling retention work correctly
- src/training/evaluate.py: greedy generation and compliance scoring are accurate
- src/training/pipeline.py: full pipeline with gate, curves, and result.json
- All three test files pass with comprehensive coverage
- Full project test suite has zero regressions
- result.json output conforms to project schema with curves block
</success_criteria>

<output>
After completion, create `.planning/phases/05-training-pipeline/05-02-SUMMARY.md`
</output>
